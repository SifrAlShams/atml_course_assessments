{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Teacher (VGG-16)"
      ],
      "metadata": {
        "id": "rnUA_n6am0CT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQIuD1Z1A7ol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412137b5-bde9-459a-f380-9836db6ed8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169M/169M [00:03<00:00, 49.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:02<00:00, 200MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Teacher VGG-16 model on cuda\n",
            "ðŸš€ Fine-tuning teacher on CIFAR-100...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:36<00:00, 10.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 3.0539 | Test Acc: 41.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:36<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] Loss: 2.0598 | Test Acc: 51.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:36<00:00, 10.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] Loss: 1.7705 | Test Acc: 54.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] Loss: 1.6048 | Test Acc: 57.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] Loss: 1.4798 | Test Acc: 59.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] Loss: 1.3817 | Test Acc: 59.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] Loss: 1.3036 | Test Acc: 60.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] Loss: 1.2257 | Test Acc: 61.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] Loss: 1.1675 | Test Acc: 62.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:37<00:00, 10.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] Loss: 1.1143 | Test Acc: 62.68%\n",
            "âœ… Training complete. Best Test Accuracy: 62.95%\n",
            "Model saved to teacher_vgg16.pth\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# STEP 1 â€” Setup and Train/Load Teacher (VGG-16) for CIFAR-100\n",
        "# ==============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Configuration\n",
        "# --------------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 10   # Fine-tuning only, not full training\n",
        "save_path = \"teacher_vgg16.pth\"\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Data Preparation\n",
        "# --------------------------------------------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                         download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=batch_size,\n",
        "                        shuffle=False, num_workers=2)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Define Teacher Model (Pretrained VGG-16)\n",
        "# --------------------------------------------------------------\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "def get_teacher_model(num_classes=100):\n",
        "    model = vgg16(weights='IMAGENET1K_V1')  # Load pretrained weights\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)  # Replace final layer\n",
        "    return model\n",
        "\n",
        "teacher = get_teacher_model(num_classes).to(device)\n",
        "print(f\"Loaded Teacher VGG-16 model on {device}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Define Loss and Optimizer\n",
        "# --------------------------------------------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(teacher.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Training Loop (Fine-tuning)\n",
        "# --------------------------------------------------------------\n",
        "def train_teacher(model, trainloader, testloader, epochs, save_path):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Evaluation\n",
        "        acc = evaluate(model, testloader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(trainloader):.4f} | Test Acc: {acc:.2f}%\")\n",
        "\n",
        "        # Save best model\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"âœ… Training complete. Best Test Accuracy: {best_acc:.2f}%\")\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Evaluation Function\n",
        "# --------------------------------------------------------------\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Run Training (if checkpoint not found)\n",
        "# --------------------------------------------------------------\n",
        "if not os.path.exists(save_path):\n",
        "    print(\"ðŸš€ Fine-tuning teacher on CIFAR-100...\")\n",
        "    train_teacher(teacher, trainloader, testloader, epochs, save_path)\n",
        "else:\n",
        "    teacher.load_state_dict(torch.load(save_path))\n",
        "    print(\"âœ… Loaded existing pretrained teacher model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRp0P4gtpx9n",
        "outputId": "ee164112-5e78-4bb7-d401-ac6bb4b2aa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# # Source path where PyTorch saved the model\n",
        "# src_path = 'teacher_vgg16.pth'\n",
        "\n",
        "# # Destination path in your Google Drive\n",
        "# dst_path = '/content/drive/MyDrive/teacher_vgg16.pth'\n",
        "\n",
        "# # Copy file to Drive\n",
        "# shutil.copy(src_path, dst_path)\n",
        "# print(\"âœ… Model saved to Google Drive at:\", dst_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y48oDiqjqCZX",
        "outputId": "47acc7a6-3a8c-4de7-b53a-8da7b83e56d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/teacher_vgg16.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision.models as models\n",
        "# from torch import nn\n",
        "\n",
        "# # Mount Drive if needed\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Define the same model structure used during training\n",
        "# model = models.vgg16(weights=None)\n",
        "\n",
        "# # Modify the classifier to match CIFAR-100 (100 output classes)\n",
        "# model.classifier[6] = nn.Linear(4096, 100)\n",
        "\n",
        "# # Load your trained weights\n",
        "# checkpoint_path = '/content/drive/MyDrive/teacher_vgg16.pth'\n",
        "# model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "# # Move to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)\n",
        "# model.eval()\n",
        "\n",
        "# print(\"ðŸš€ Model loaded successfully with 100-class output and ready for inference!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34Z0tjTlqPHH",
        "outputId": "eb981523-763d-41ef-99b0-7f208d99a599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ðŸš€ Model loaded successfully with 100-class output and ready for inference!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Student Independent"
      ],
      "metadata": {
        "id": "uXPMy2a__iIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Independent Student (SI) Training on CIFAR-100\n",
        "----------------------------------------------\n",
        "This trains a VGG-11 student model from scratch *without* any teacher guidance.\n",
        "It serves as the baseline for Knowledge Distillation comparisons.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# ======================================================\n",
        "# 1. Device Setup\n",
        "# ======================================================\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "# ======================================================\n",
        "# 2. Dataset Preparation\n",
        "# ======================================================\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
        "                         (0.2673, 0.2564, 0.2762)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
        "                         (0.2673, 0.2564, 0.2762)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
        "\n",
        "# ======================================================\n",
        "# 3. Model Definition (VGG11)\n",
        "# ======================================================\n",
        "from torchvision.models import vgg11\n",
        "\n",
        "def build_student(num_classes=100):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "student = build_student(num_classes=100).to(DEVICE)\n",
        "\n",
        "# ======================================================\n",
        "# 4. Loss, Optimizer, and Scheduler\n",
        "# ======================================================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(student.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
        "\n",
        "# ======================================================\n",
        "# 5. Training & Evaluation Loops\n",
        "# ======================================================\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "best_acc = 0.0\n",
        "num_epochs = 30\n",
        "save_path = \"student_vgg11_SI.pth\"\n",
        "\n",
        "# ======================================================\n",
        "# 6. Training Loop\n",
        "# ======================================================\n",
        "for epoch in range(num_epochs):\n",
        "    student.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = student(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=running_loss / (len(pbar) + 1))\n",
        "\n",
        "    scheduler.step()\n",
        "    val_acc = evaluate(student, testloader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(trainloader):.4f} - Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(student.state_dict(), save_path)\n",
        "        print(f\"âœ… New best model saved with accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "print(f\"\\nTraining finished! Best validation accuracy: {best_acc:.2f}%\")\n",
        "print(f\"Model saved to: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Nw1rxB_gXt",
        "outputId": "fad4c3b5-162d-4df9-e400-1cec70a1711a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169M/169M [00:07<00:00, 24.0MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.96it/s, loss=4.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Loss: 4.3905 - Val Acc: 5.24%\n",
            "âœ… New best model saved with accuracy: 5.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.31it/s, loss=3.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Loss: 3.9548 - Val Acc: 10.19%\n",
            "âœ… New best model saved with accuracy: 10.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.41it/s, loss=3.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Loss: 3.7013 - Val Acc: 14.04%\n",
            "âœ… New best model saved with accuracy: 14.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.31it/s, loss=3.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Loss: 3.4349 - Val Acc: 19.09%\n",
            "âœ… New best model saved with accuracy: 19.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.98it/s, loss=3.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Loss: 3.2012 - Val Acc: 23.14%\n",
            "âœ… New best model saved with accuracy: 23.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.20it/s, loss=2.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Loss: 2.9658 - Val Acc: 26.31%\n",
            "âœ… New best model saved with accuracy: 26.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.07it/s, loss=2.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Loss: 2.7840 - Val Acc: 31.22%\n",
            "âœ… New best model saved with accuracy: 31.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.04it/s, loss=2.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Loss: 2.6271 - Val Acc: 34.45%\n",
            "âœ… New best model saved with accuracy: 34.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.08it/s, loss=2.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Loss: 2.4821 - Val Acc: 37.74%\n",
            "âœ… New best model saved with accuracy: 37.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.14it/s, loss=2.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Loss: 2.3557 - Val Acc: 40.63%\n",
            "âœ… New best model saved with accuracy: 40.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.11it/s, loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Loss: 2.2327 - Val Acc: 41.48%\n",
            "âœ… New best model saved with accuracy: 41.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.08it/s, loss=2.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Loss: 2.1254 - Val Acc: 43.81%\n",
            "âœ… New best model saved with accuracy: 43.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.96it/s, loss=2.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Loss: 2.0222 - Val Acc: 45.80%\n",
            "âœ… New best model saved with accuracy: 45.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 13.02it/s, loss=1.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Loss: 1.9483 - Val Acc: 47.00%\n",
            "âœ… New best model saved with accuracy: 47.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.04it/s, loss=1.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Loss: 1.8642 - Val Acc: 48.21%\n",
            "âœ… New best model saved with accuracy: 48.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.04it/s, loss=1.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Loss: 1.8005 - Val Acc: 49.15%\n",
            "âœ… New best model saved with accuracy: 49.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.92it/s, loss=1.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Loss: 1.7280 - Val Acc: 50.41%\n",
            "âœ… New best model saved with accuracy: 50.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.94it/s, loss=1.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Loss: 1.6700 - Val Acc: 51.43%\n",
            "âœ… New best model saved with accuracy: 51.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.07it/s, loss=1.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Loss: 1.5912 - Val Acc: 51.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.11it/s, loss=1.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Loss: 1.5445 - Val Acc: 50.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.96it/s, loss=1.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Loss: 1.4889 - Val Acc: 53.53%\n",
            "âœ… New best model saved with accuracy: 53.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.05it/s, loss=1.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Loss: 1.4384 - Val Acc: 53.63%\n",
            "âœ… New best model saved with accuracy: 53.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.99it/s, loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Loss: 1.3863 - Val Acc: 53.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.89it/s, loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Loss: 1.3480 - Val Acc: 54.52%\n",
            "âœ… New best model saved with accuracy: 54.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:29<00:00, 13.05it/s, loss=1.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Loss: 1.2968 - Val Acc: 55.26%\n",
            "âœ… New best model saved with accuracy: 55.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.99it/s, loss=1.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Loss: 1.2621 - Val Acc: 56.29%\n",
            "âœ… New best model saved with accuracy: 56.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.97it/s, loss=1.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Loss: 1.2048 - Val Acc: 55.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.89it/s, loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Loss: 1.1816 - Val Acc: 55.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 13.01it/s, loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Loss: 1.1310 - Val Acc: 55.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.86it/s, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Loss: 1.0853 - Val Acc: 56.81%\n",
            "âœ… New best model saved with accuracy: 56.81%\n",
            "\n",
            "Training finished! Best validation accuracy: 56.81%\n",
            "Model saved to: student_vgg11_SI.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Local model file (after training)\n",
        "# local_path = \"student_vgg11_SI.pth\"\n",
        "\n",
        "# # Destination in Google Drive\n",
        "# drive_path = \"/content/drive/MyDrive/student_vgg11_SI.pth\"\n",
        "\n",
        "# # Copy file\n",
        "# shutil.copy(local_path, drive_path)\n",
        "# print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TAo-4rkF-Lu",
        "outputId": "7d8b9363-dfce-4078-b6be-1fd4bc311a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_SI.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGIT MATCHING"
      ],
      "metadata": {
        "id": "HaB0gNpem7yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# KNOWLEDGE DISTILLATION â€” LOGIT MATCHING (TUNED VERSION)\n",
        "# ==============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg11, vgg16\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 128\n",
        "num_classes = 100\n",
        "epochs = 30\n",
        "teacher_ckpt = \"teacher_vgg16.pth\"\n",
        "student_ckpt = \"student_vgg11_LM_tuned.pth\"\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Data setup\n",
        "# --------------------------------------------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                         download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Model definitions\n",
        "# --------------------------------------------------------------\n",
        "def get_teacher(num_classes=100):\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def get_student(num_classes=100):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "teacher = get_teacher(num_classes).to(device)\n",
        "teacher.load_state_dict(torch.load(teacher_ckpt, map_location=device))\n",
        "teacher.eval()\n",
        "\n",
        "student = get_student(num_classes).to(device)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Evaluation\n",
        "# --------------------------------------------------------------\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            out = model(imgs)\n",
        "            _, preds = torch.max(out, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# KD Loss\n",
        "# --------------------------------------------------------------\n",
        "class KDLoss(nn.Module):\n",
        "    def __init__(self, T=4.0, alpha=0.5):\n",
        "        super(KDLoss, self).__init__()\n",
        "        self.T = T\n",
        "        self.alpha = alpha\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        ce_loss = self.ce(student_logits, labels)\n",
        "        soft_teacher = F.softmax(teacher_logits.detach() / self.T, dim=1)\n",
        "        soft_student = F.log_softmax(student_logits / self.T, dim=1)\n",
        "        kl_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (self.T ** 2)\n",
        "        return self.alpha * ce_loss + (1 - self.alpha) * kl_loss\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Training\n",
        "# --------------------------------------------------------------\n",
        "def train_kd(student, teacher, trainloader, testloader, epochs=30, T=4.0, alpha=0.5, lr=0.01):\n",
        "    criterion = KDLoss(T=T, alpha=alpha)\n",
        "    optimizer = optim.SGD(student.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        running_loss = 0.0\n",
        "        for imgs, labels in tqdm(trainloader, desc=f\"KD Epoch {epoch+1}/{epochs}\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(imgs)\n",
        "\n",
        "            student_logits = student(imgs)\n",
        "            loss = criterion(student_logits, teacher_logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student.parameters(), 5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "        acc = evaluate(student, testloader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(trainloader):.4f} | Acc: {acc:.2f}%\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(student.state_dict(), student_ckpt)\n",
        "\n",
        "    print(f\"âœ… KD Training complete. Best Acc: {best_acc:.2f}% | Saved at {student_ckpt}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Run tuned KD training\n",
        "# --------------------------------------------------------------\n",
        "train_kd(student, teacher, trainloader, testloader,\n",
        "         epochs=30, T=4.0, alpha=0.5, lr=0.01)\n"
      ],
      "metadata": {
        "id": "PDWOV7ECJ7U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb121f05-70f2-4ab6-8cf7-388bcfc2ad40"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30] | Loss: 4.9112 | Acc: 6.49%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/30] | Loss: 4.2187 | Acc: 12.25%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/30] | Loss: 3.7186 | Acc: 20.18%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/30] | Loss: 3.2067 | Acc: 25.83%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/30] | Loss: 2.8294 | Acc: 30.06%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/30] | Loss: 2.5408 | Acc: 34.17%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/30] | Loss: 2.3129 | Acc: 38.18%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/30] | Loss: 2.1085 | Acc: 40.72%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/30] | Loss: 1.9643 | Acc: 43.04%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/30] | Loss: 1.8255 | Acc: 45.14%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/30] | Loss: 1.7218 | Acc: 46.32%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/30] | Loss: 1.6233 | Acc: 49.73%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/30] | Loss: 1.5265 | Acc: 50.67%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/30] | Loss: 1.4531 | Acc: 51.66%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/30] | Loss: 1.3862 | Acc: 52.98%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/30] | Loss: 1.3228 | Acc: 54.11%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/30] | Loss: 1.2693 | Acc: 55.20%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/30] | Loss: 1.2123 | Acc: 55.34%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/30] | Loss: 1.1698 | Acc: 55.72%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/30] | Loss: 1.1250 | Acc: 57.23%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/30] | Loss: 1.0898 | Acc: 58.03%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/30] | Loss: 1.0595 | Acc: 58.66%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/30] | Loss: 1.0329 | Acc: 58.55%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/30] | Loss: 1.0070 | Acc: 58.75%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/30] | Loss: 0.9875 | Acc: 59.24%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/30] | Loss: 0.9715 | Acc: 59.25%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/30] | Loss: 0.9614 | Acc: 59.38%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/30] | Loss: 0.9532 | Acc: 59.61%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "KD Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/30] | Loss: 0.9458 | Acc: 59.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "KD Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30] | Loss: 0.9396 | Acc: 59.60%\n",
            "âœ… KD Training complete. Best Acc: 59.61% | Saved at student_vgg11_LM_tuned.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Local model file (after training)\n",
        "# local_path = \"student_vgg11_LM_tuned.pth\"\n",
        "\n",
        "# # Destination in Google Drive\n",
        "# drive_path = \"/content/drive/MyDrive/student_vgg11_LM_tuned.pth\"\n",
        "\n",
        "# # Copy file\n",
        "# shutil.copy(local_path, drive_path)\n",
        "# print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_72bo7NwnGk",
        "outputId": "bd6def2b-6fe7-4416-e5dd-c3420321cf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_LM_tuned.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Smoothing Regularization (LSR)"
      ],
      "metadata": {
        "id": "NcaxNf3unCLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Label Smoothing Regularization (LSR) Implementation\n",
        "# ==============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1. Define Label Smoothing Loss\n",
        "# --------------------------------------------------------------\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes=100, smoothing=0.1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=-1)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=-1))\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. CIFAR-100 Data Loaders\n",
        "# --------------------------------------------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                         (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. Define Student Model (VGG-11)\n",
        "# --------------------------------------------------------------\n",
        "def get_vgg11_student():\n",
        "    model = models.vgg11_bn(weights=None, num_classes=100)\n",
        "    return model.to(device)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. Evaluation Function\n",
        "# --------------------------------------------------------------\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. Training Function (Label Smoothing)\n",
        "# --------------------------------------------------------------\n",
        "def train_label_smoothing(model, trainloader, testloader, epochs=30, lr=0.01, smoothing=0.1):\n",
        "    criterion = LabelSmoothingLoss(classes=100, smoothing=smoothing)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in tqdm(trainloader, desc=f\"LS Epoch {epoch+1}/{epochs}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "        acc = evaluate(model, testloader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(trainloader):.4f} | Acc: {acc:.2f}%\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(model.state_dict(), \"student_vgg11_LS.pth\")\n",
        "\n",
        "    print(f\"âœ… Label Smoothing Training complete. Best Acc: {best_acc:.2f}% | Saved at student_vgg11_LS.pth\")\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 6. Run Training\n",
        "# --------------------------------------------------------------\n",
        "student_lsr = get_vgg11_student()\n",
        "acc_ls = train_label_smoothing(student_lsr, trainloader, testloader, epochs=30, lr=0.01, smoothing=0.1)\n"
      ],
      "metadata": {
        "id": "hh46Gc8iEjRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adea8abb-9e47-4d5c-87c7-34f1229e3335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30] | Loss: 4.2494 | Acc: 11.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30] | Loss: 3.9034 | Acc: 15.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30] | Loss: 3.6888 | Acc: 21.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30] | Loss: 3.4815 | Acc: 26.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30] | Loss: 3.3090 | Acc: 28.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30] | Loss: 3.1604 | Acc: 33.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30] | Loss: 3.0260 | Acc: 34.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30] | Loss: 2.9116 | Acc: 37.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30] | Loss: 2.7997 | Acc: 42.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30] | Loss: 2.7047 | Acc: 44.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30] | Loss: 2.6211 | Acc: 44.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30] | Loss: 2.5354 | Acc: 46.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30] | Loss: 2.4554 | Acc: 46.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30] | Loss: 2.3874 | Acc: 50.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30] | Loss: 2.3174 | Acc: 52.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30] | Loss: 2.2501 | Acc: 53.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30] | Loss: 2.1825 | Acc: 54.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30] | Loss: 2.1231 | Acc: 55.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30] | Loss: 2.0648 | Acc: 55.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30] | Loss: 2.0141 | Acc: 56.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30] | Loss: 1.9596 | Acc: 57.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:31<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30] | Loss: 1.9057 | Acc: 58.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30] | Loss: 1.8520 | Acc: 58.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30] | Loss: 1.8106 | Acc: 60.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30] | Loss: 1.7702 | Acc: 60.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30] | Loss: 1.7363 | Acc: 60.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30] | Loss: 1.7083 | Acc: 60.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30] | Loss: 1.6873 | Acc: 60.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30] | Loss: 1.6666 | Acc: 60.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LS Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:30<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30] | Loss: 1.6610 | Acc: 61.11%\n",
            "âœ… Label Smoothing Training complete. Best Acc: 61.11% | Saved at student_vgg11_LS.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Local model file (after training)\n",
        "# local_path = \"student_vgg11_LS.pth\"\n",
        "\n",
        "# # Destination in Google Drive\n",
        "# drive_path = \"/content/drive/MyDrive/student_vgg11_LS.pth\"\n",
        "\n",
        "# # Copy file\n",
        "# shutil.copy(local_path, drive_path)\n",
        "# print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMXUquDdyLK-",
        "outputId": "f6f3e758-a386-40e8-e73d-55d50076b9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_LS.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decoupled Knowledge Distillation (DKD)"
      ],
      "metadata": {
        "id": "eUTP__IbnLAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "task3_dkd.py\n",
        "\n",
        "Decoupled Knowledge Distillation (DKD) training script for:\n",
        "- Teacher: pretrained/fine-tuned VGG-16 on CIFAR-100 (teacher_vgg16.pth)\n",
        "- Student: VGG-11 trained with DKD\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg11, vgg16\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------\n",
        "# Config\n",
        "# ---------------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 128\n",
        "NUM_CLASSES = 100\n",
        "NUM_EPOCHS = 30\n",
        "TEACHER_CKPT = \"teacher_vgg16.pth\"\n",
        "STUDENT_OUT = \"student_vgg11_DKD.pth\"\n",
        "LR = 0.01\n",
        "WEIGHT_DECAY = 5e-4\n",
        "MOMENTUM = 0.9\n",
        "\n",
        "# DKD hyperparameters\n",
        "TEMPERATURE = 4.0           # T\n",
        "LAMBDA_CE = 0.5             # weight for CE(hard labels) vs distillation\n",
        "ALPHA_DKD = 0.5             # weight for TCKD (target)\n",
        "BETA_DKD = 0.5              # weight for NCKD (non-target)\n",
        "EPS = 1e-8\n",
        "\n",
        "# ---------------------------\n",
        "# Helpers: data loaders\n",
        "# ---------------------------\n",
        "def get_dataloaders(batch_size=BATCH_SIZE, num_workers=2):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                             (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                             (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    return trainloader, testloader\n",
        "\n",
        "# ---------------------------\n",
        "# Models\n",
        "# ---------------------------\n",
        "def build_teacher(num_classes=NUM_CLASSES):\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def build_student(num_classes=NUM_CLASSES):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation\n",
        "# ---------------------------\n",
        "def evaluate(model, dataloader, device=DEVICE):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# ---------------------------\n",
        "# DKD loss implementation\n",
        "# ---------------------------\n",
        "class DKDLoss(nn.Module):\n",
        "    def __init__(self, T=TEMPERATURE, alpha=ALPHA_DKD, beta=BETA_DKD, eps=EPS):\n",
        "        super().__init__()\n",
        "        self.T = float(T)\n",
        "        self.alpha = float(alpha)\n",
        "        self.beta = float(beta)\n",
        "        self.eps = float(eps)\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, targets):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "          - student_logits: (B, C)\n",
        "          - teacher_logits: (B, C)\n",
        "          - targets: (B,) long\n",
        "        Returns: scalar DKD distillation loss\n",
        "        \"\"\"\n",
        "        B, C = student_logits.shape\n",
        "        T = self.T\n",
        "        # teacher and student probabilities with temperature\n",
        "        p_t = F.softmax(teacher_logits / T, dim=1)            # (B, C)\n",
        "        p_s = F.softmax(student_logits / T, dim=1)            # (B, C)\n",
        "\n",
        "        # target-class probabilities\n",
        "        targets_col = targets.view(-1, 1)                     # (B,1)\n",
        "        p_t_true = p_t.gather(1, targets_col).squeeze(1)      # (B,)\n",
        "        p_s_true = p_s.gather(1, targets_col).squeeze(1)      # (B,)\n",
        "\n",
        "        # === TCKD: target class knowledge ===\n",
        "        # Weighted negative log-likelihood of student true prob, weighted by teacher true prob\n",
        "        # tckd = - mean( p_t_true * log(p_s_true) )\n",
        "        tckd = - torch.mean(p_t_true.detach() * torch.log(p_s_true + self.eps))\n",
        "\n",
        "        # === NCKD: non-target knowledge ===\n",
        "        # mask out true class\n",
        "        mask = torch.ones_like(p_t, device=p_t.device)\n",
        "        mask.scatter_(1, targets_col, 0.0)                    # zeros at true class positions\n",
        "\n",
        "        # teacher and student non-target distributions\n",
        "        p_t_nt = p_t * mask                                    # (B, C) with zero at target\n",
        "        p_s_nt = p_s * mask\n",
        "\n",
        "        # normalize so each row sums to 1 over non-target classes (avoid divide by zero)\n",
        "        denom_t = p_t_nt.sum(dim=1, keepdim=True) + self.eps\n",
        "        denom_s = p_s_nt.sum(dim=1, keepdim=True) + self.eps\n",
        "        p_t_nt_norm = p_t_nt / denom_t                         # (B, C)\n",
        "        p_s_nt_norm = p_s_nt / denom_s\n",
        "\n",
        "        # compute KL divergence per sample between teacher non-target and student non-target\n",
        "        # KL( p_t_nt_norm || p_s_nt_norm ) = sum p_t_nt_norm * (log p_t_nt_norm - log p_s_nt_norm)\n",
        "        # sum across classes then mean over batch\n",
        "        kl_nt = p_t_nt_norm * (torch.log(p_t_nt_norm + self.eps) - torch.log(p_s_nt_norm + self.eps))\n",
        "        nckd = torch.mean(torch.sum(kl_nt, dim=1))\n",
        "\n",
        "        # combine with weights. Note: scale NCKD by T^2 (as usual for scaled soft targets)\n",
        "        loss = self.alpha * tckd + self.beta * (T * T) * nckd\n",
        "        return loss\n",
        "\n",
        "# ---------------------------\n",
        "# Training routine\n",
        "# ---------------------------\n",
        "def train_dkd(teacher, student, trainloader, testloader,\n",
        "              epochs=NUM_EPOCHS, lr=LR, lambda_ce=LAMBDA_CE, device=DEVICE):\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "    dkd_criterion = DKDLoss(T=TEMPERATURE, alpha=ALPHA_DKD, beta=BETA_DKD, eps=EPS)\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(student.parameters(), lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        student.train()\n",
        "        running_loss = 0.0\n",
        "        iters = 0\n",
        "        pbar = tqdm(trainloader, desc=f\"DKD Epoch {epoch}/{epochs}\")\n",
        "        for imgs, labels in pbar:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            with torch.no_grad():\n",
        "                t_logits = teacher(imgs)        # teacher frozen\n",
        "\n",
        "            s_logits = student(imgs)\n",
        "            loss_ce = ce(s_logits, labels)\n",
        "            loss_dkd = dkd_criterion(s_logits, t_logits, labels)\n",
        "\n",
        "            loss = lambda_ce * loss_ce + (1.0 - lambda_ce) * loss_dkd\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += float(loss.item())\n",
        "            iters += 1\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_loss = running_loss / max(iters, 1)\n",
        "        acc = evaluate(student, testloader, device)\n",
        "        print(f\"Epoch {epoch}/{epochs} - Loss: {avg_loss:.4f} - Val Acc: {acc:.2f}%\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            torch.save(student.state_dict(), STUDENT_OUT)\n",
        "            print(f\"  -> New best saved: {STUDENT_OUT} (acc {best_acc:.2f}%)\")\n",
        "\n",
        "    print(f\"DKD training finished. Best Val Acc: {best_acc:.2f}%\")\n",
        "\n",
        "# ---------------------------\n",
        "# Main\n",
        "# ---------------------------\n",
        "def main():\n",
        "    trainloader, testloader = get_dataloaders(batch_size=BATCH_SIZE, num_workers=2)\n",
        "\n",
        "    # load teacher checkpoint\n",
        "    if not os.path.exists(TEACHER_CKPT):\n",
        "        raise FileNotFoundError(f\"Teacher checkpoint not found: {TEACHER_CKPT}. Please place it here.\")\n",
        "    teacher = build_teacher(NUM_CLASSES).to(DEVICE)\n",
        "    teacher.load_state_dict(torch.load(TEACHER_CKPT, map_location=DEVICE))\n",
        "    teacher.eval()\n",
        "    print(\"Loaded teacher:\", TEACHER_CKPT)\n",
        "\n",
        "    # build student\n",
        "    student = build_student(NUM_CLASSES).to(DEVICE)\n",
        "    print(\"Student built, start DKD training...\")\n",
        "\n",
        "    train_dkd(teacher, student, trainloader, testloader,\n",
        "              epochs=NUM_EPOCHS, lr=LR, lambda_ce=LAMBDA_CE, device=DEVICE)\n",
        "\n",
        "    final_acc = evaluate(student, testloader, DEVICE)\n",
        "    print(\"Final student accuracy (DKD):\", final_acc)\n",
        "    print(\"Saved best student to\", STUDENT_OUT)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRS3JmHVxj8y",
        "outputId": "688ce2d4-e757-4fdf-e535-5fa64a93ebde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded teacher: teacher_vgg16.pth\n",
            "Student built, start DKD training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Loss: 3.1099 - Val Acc: 6.54%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 6.54%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Loss: 2.7394 - Val Acc: 11.74%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 11.74%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Loss: 2.5272 - Val Acc: 16.31%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 16.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Loss: 2.3320 - Val Acc: 21.47%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 21.47%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Loss: 2.1454 - Val Acc: 24.43%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 24.43%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Loss: 1.9695 - Val Acc: 29.51%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 29.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Loss: 1.8501 - Val Acc: 32.48%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 32.48%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Loss: 1.7418 - Val Acc: 35.00%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 35.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Loss: 1.6399 - Val Acc: 37.97%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 37.97%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Loss: 1.5527 - Val Acc: 40.05%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 40.05%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Loss: 1.4753 - Val Acc: 43.49%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 43.49%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Loss: 1.4064 - Val Acc: 44.83%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 44.83%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Loss: 1.3435 - Val Acc: 46.67%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 46.67%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Loss: 1.2947 - Val Acc: 48.43%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 48.43%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Loss: 1.2450 - Val Acc: 49.10%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 49.10%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Loss: 1.1964 - Val Acc: 51.27%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 51.27%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Loss: 1.1571 - Val Acc: 52.47%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 52.47%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Loss: 1.1150 - Val Acc: 52.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Loss: 1.0782 - Val Acc: 53.57%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 53.57%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Loss: 1.0480 - Val Acc: 54.07%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 54.07%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Loss: 1.0224 - Val Acc: 54.41%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 54.41%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Loss: 0.9935 - Val Acc: 55.71%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 55.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Loss: 0.9686 - Val Acc: 55.75%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 55.75%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Loss: 0.9540 - Val Acc: 56.78%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 56.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Loss: 0.9305 - Val Acc: 56.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Loss: 0.9161 - Val Acc: 57.24%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 57.24%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Loss: 0.9039 - Val Acc: 57.88%\n",
            "  -> New best saved: student_vgg11_DKD.pth (acc 57.88%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Loss: 0.8959 - Val Acc: 57.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Loss: 0.8907 - Val Acc: 57.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DKD Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:41<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Loss: 0.8871 - Val Acc: 57.77%\n",
            "DKD training finished. Best Val Acc: 57.88%\n",
            "Final student accuracy (DKD): 57.77\n",
            "Saved best student to student_vgg11_DKD.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Local model file (after training)\n",
        "# local_path = \"student_vgg11_DKD.pth\"\n",
        "\n",
        "# # Destination in Google Drive\n",
        "# drive_path = \"/content/drive/MyDrive/student_vgg11_DKD.pth\"\n",
        "\n",
        "# # Copy file\n",
        "# shutil.copy(local_path, drive_path)\n",
        "# print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCyBzSc8_mrl",
        "outputId": "1d54fb51-fb25-460b-fc0e-2afbcc0b8b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_DKD.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hint Distillation"
      ],
      "metadata": {
        "id": "6WBPJjnSnR_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hint_distill.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ============================================================\n",
        "# 1. Utility functions\n",
        "# ============================================================\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def accuracy(output, target):\n",
        "    _, preds = torch.max(output, 1)\n",
        "    return torch.sum(preds == target).item() / target.size(0)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Dataset and Dataloader\n",
        "# ============================================================\n",
        "\n",
        "def get_dataloaders(batch_size=128):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                             (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                             (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR100(root=\"./data\", train=True,\n",
        "                                 download=True, transform=transform_train)\n",
        "    testset = datasets.CIFAR100(root=\"./data\", train=False,\n",
        "                                download=True, transform=transform_test)\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size,\n",
        "                            shuffle=False, num_workers=2)\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Model setup (Teacher, Student, Adapter)\n",
        "# ============================================================\n",
        "\n",
        "class HintAdapter(nn.Module):\n",
        "    \"\"\"1x1 conv to align student feature channels to teacher.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "def get_teacher_student(device):\n",
        "    # Teacher: pretrained VGG16\n",
        "    teacher = models.vgg16(weights='IMAGENET1K_V1')\n",
        "    teacher.classifier[6] = nn.Linear(4096, 100)\n",
        "    teacher.load_state_dict(torch.load('teacher_vgg16.pth'))\n",
        "    teacher = teacher.to(device)\n",
        "    teacher.eval()\n",
        "    for p in teacher.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # Student: VGG11\n",
        "    student = models.vgg11()\n",
        "    student.classifier[6] = nn.Linear(4096, 100)\n",
        "    student = student.to(device)\n",
        "\n",
        "    # ---- Find convolution layers dynamically ----\n",
        "    teacher_conv_layers = [m for m in teacher.features if isinstance(m, nn.Conv2d)]\n",
        "    student_conv_layers = [m for m in student.features if isinstance(m, nn.Conv2d)]\n",
        "\n",
        "    # Choose middle convolution layer pair (e.g., 4th conv)\n",
        "    t_layer = teacher_conv_layers[4]\n",
        "    s_layer = student_conv_layers[3]\n",
        "\n",
        "    # We'll need to hook these, so we must find their indices in .features\n",
        "    t_index = list(teacher.features).index(t_layer)\n",
        "    s_index = list(student.features).index(s_layer)\n",
        "\n",
        "    # Adapter to match feature channel dims\n",
        "    t_channels = t_layer.out_channels\n",
        "    s_channels = s_layer.out_channels\n",
        "    adapter = HintAdapter(s_channels, t_channels).to(device)\n",
        "\n",
        "    return teacher, student, adapter, t_index, s_index\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Hook functions to extract feature maps\n",
        "# ============================================================\n",
        "\n",
        "def get_feature_hook(storage_dict, name):\n",
        "    def hook(module, input, output):\n",
        "        storage_dict[name] = output\n",
        "    return hook\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Training loop\n",
        "# ============================================================\n",
        "\n",
        "def train_hint_kd(epochs=30, batch_size=128, lr=0.01, lambda_hint=0.5, device='cuda'):\n",
        "    set_seed(42)\n",
        "    trainloader, testloader = get_dataloaders(batch_size)\n",
        "    teacher, student, adapter, t_layer, s_layer = get_teacher_student(device)\n",
        "\n",
        "    # Feature storage\n",
        "    feat_t, feat_s = {}, {}\n",
        "    teacher.features[t_layer].register_forward_hook(get_feature_hook(feat_t, \"t\"))\n",
        "    student.features[s_layer].register_forward_hook(get_feature_hook(feat_s, \"s\"))\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.SGD(\n",
        "        list(student.parameters()) + list(adapter.parameters()),\n",
        "        lr=lr, momentum=0.9, weight_decay=5e-4\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    best_acc = 0\n",
        "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        running_loss = 0\n",
        "        running_acc = 0\n",
        "\n",
        "        for imgs, labels in tqdm(trainloader, desc=f\"Epoch [{epoch+1}/{epochs}]\"):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _ = teacher(imgs)\n",
        "            _ = student(imgs)\n",
        "\n",
        "            # Feature distillation loss\n",
        "            loss_hint = mse_loss(adapter(feat_s[\"s\"]), feat_t[\"t\"].detach())\n",
        "\n",
        "            # Classification loss\n",
        "            outputs = student(imgs)\n",
        "            loss_ce = ce_loss(outputs, labels)\n",
        "\n",
        "            # Combine losses\n",
        "            loss = (1 - lambda_hint) * loss_ce + lambda_hint * loss_hint\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_acc += accuracy(outputs, labels)\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_train_loss = running_loss / len(trainloader)\n",
        "        avg_train_acc = running_acc / len(trainloader)\n",
        "\n",
        "        # Validation\n",
        "        student.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in testloader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = student(imgs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        val_acc = correct / total * 100\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {avg_train_loss:.4f} | \"\n",
        "              f\"Train Acc: {avg_train_acc*100:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(student.state_dict(), \"student_vgg11_hints.pth\")\n",
        "\n",
        "    print(f\"âœ… Hint KD complete. Best Acc: {best_acc:.2f}% | \"\n",
        "          f\"Saved at student_vgg11_hints.pth\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. Run directly\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    train_hint_kd(epochs=30, batch_size=128, lr=0.01, lambda_hint=0.5, device=device)\n"
      ],
      "metadata": {
        "id": "Bz2QTwp43gcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d19749-2334-4107-822b-65fec5845079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30] | Loss: 5.2150 | Train Acc: 1.66% | Val Acc: 4.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30] | Loss: 4.4446 | Train Acc: 6.79% | Val Acc: 10.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30] | Loss: 3.9338 | Train Acc: 12.36% | Val Acc: 16.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30] | Loss: 3.5926 | Train Acc: 17.11% | Val Acc: 21.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30] | Loss: 3.3435 | Train Acc: 21.22% | Val Acc: 27.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30] | Loss: 3.1127 | Train Acc: 25.54% | Val Acc: 28.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30] | Loss: 2.9311 | Train Acc: 29.29% | Val Acc: 34.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30] | Loss: 2.7690 | Train Acc: 32.88% | Val Acc: 35.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30] | Loss: 2.6499 | Train Acc: 35.47% | Val Acc: 38.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30] | Loss: 2.5413 | Train Acc: 37.95% | Val Acc: 41.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30] | Loss: 2.4400 | Train Acc: 40.64% | Val Acc: 41.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30] | Loss: 2.3549 | Train Acc: 42.71% | Val Acc: 42.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30] | Loss: 2.2869 | Train Acc: 44.58% | Val Acc: 45.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30] | Loss: 2.2167 | Train Acc: 46.68% | Val Acc: 47.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30] | Loss: 2.1468 | Train Acc: 48.78% | Val Acc: 47.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30] | Loss: 2.0898 | Train Acc: 50.61% | Val Acc: 49.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30] | Loss: 2.0306 | Train Acc: 52.30% | Val Acc: 50.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30] | Loss: 1.9820 | Train Acc: 54.05% | Val Acc: 50.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30] | Loss: 1.9336 | Train Acc: 55.69% | Val Acc: 52.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30] | Loss: 1.8847 | Train Acc: 57.28% | Val Acc: 53.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30] | Loss: 1.8445 | Train Acc: 58.75% | Val Acc: 54.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [22/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30] | Loss: 1.8070 | Train Acc: 60.16% | Val Acc: 54.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [23/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30] | Loss: 1.7724 | Train Acc: 61.55% | Val Acc: 54.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [24/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30] | Loss: 1.7435 | Train Acc: 62.78% | Val Acc: 55.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [25/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30] | Loss: 1.7148 | Train Acc: 63.78% | Val Acc: 55.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [26/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30] | Loss: 1.6930 | Train Acc: 65.09% | Val Acc: 56.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30] | Loss: 1.6779 | Train Acc: 65.61% | Val Acc: 56.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [28/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30] | Loss: 1.6610 | Train Acc: 66.43% | Val Acc: 56.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [29/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30] | Loss: 1.6505 | Train Acc: 67.03% | Val Acc: 56.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [30/30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:49<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30] | Loss: 1.6468 | Train Acc: 67.18% | Val Acc: 56.70%\n",
            "âœ… Hint KD complete. Best Acc: 56.83% | Saved at student_vgg11_hints.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Local model file (after training)\n",
        "local_path = \"student_vgg11_hints.pth\"\n",
        "\n",
        "# Destination in Google Drive\n",
        "drive_path = \"/content/drive/MyDrive/student_vgg11_hints.pth\"\n",
        "\n",
        "# Copy file\n",
        "shutil.copy(local_path, drive_path)\n",
        "print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_6cuyMtHnsa",
        "outputId": "df7b34c7-2625-402e-8998-a36bb589ad95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_hints.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contrastive Representation Distillation (CRD)"
      ],
      "metadata": {
        "id": "d9xZ42QoMwsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crd_distill_run.py\n",
        "# Contrastive Representation Distillation (in-batch InfoNCE) for VGG16 -> VGG11 on CIFAR-100\n",
        "# Saves best student as: student_vgg11_CRD.pth\n",
        "# Logs to: crd_training_log.csv\n",
        "\n",
        "import os\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg11, vgg16\n",
        "\n",
        "# -----------------------\n",
        "# Config / Hyperparams\n",
        "# -----------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 30\n",
        "NUM_CLASSES = 100\n",
        "LR = 0.01\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 5e-4\n",
        "CLIP_GRAD = 5.0\n",
        "SEED = 42\n",
        "PRINT_EVERY = 1\n",
        "\n",
        "# CRD-specific\n",
        "PROJ_DIM = 256        # projection embedding dimension\n",
        "TAU = 0.07            # contrastive temperature\n",
        "LAMBDA_CRD = 1.0      # weight for contrastive loss vs CE\n",
        "\n",
        "TEACHER_CKPT = \"/content/drive/MyDrive/teacher_vgg16.pth\"\n",
        "STUDENT_OUT = \"student_vgg11_CRD.pth\"\n",
        "LOG_CSV = \"crd_training_log.csv\"\n",
        "\n",
        "# -----------------------\n",
        "# Utilities\n",
        "# -----------------------\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    # deterministic behavior (may slow training)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# -----------------------\n",
        "# Data\n",
        "# -----------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),(0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408),(0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# -----------------------\n",
        "# Model builders\n",
        "# -----------------------\n",
        "def build_teacher(num_classes=NUM_CLASSES):\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def build_student(num_classes=NUM_CLASSES):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "# -----------------------\n",
        "# Feature hook helper\n",
        "# -----------------------\n",
        "def register_last_feature_hook(model, storage_dict, key=\"feat\"):\n",
        "    \"\"\"\n",
        "    Registers a forward hook on the last conv layer in model.features to capture the conv feature map.\n",
        "    \"\"\"\n",
        "    last_conv = None\n",
        "    for m in model.features:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            last_conv = m\n",
        "    if last_conv is None:\n",
        "        raise RuntimeError(\"No Conv2d found in model.features\")\n",
        "    handle = last_conv.register_forward_hook(lambda module, inp, out: storage_dict.update({key: out}))\n",
        "    return handle\n",
        "\n",
        "# -----------------------\n",
        "# Projection head\n",
        "# -----------------------\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim, proj_dim=PROJ_DIM):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_dim, proj_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# -----------------------\n",
        "# In-batch InfoNCE loss\n",
        "# -----------------------\n",
        "def info_nce_loss(student_proj, teacher_proj, tau=TAU):\n",
        "    \"\"\"\n",
        "    student_proj: (B, D)\n",
        "    teacher_proj: (B, D)\n",
        "    returns scalar loss (average over batch)\n",
        "    \"\"\"\n",
        "    student_norm = F.normalize(student_proj, dim=1, p=2)\n",
        "    teacher_norm = F.normalize(teacher_proj, dim=1, p=2)\n",
        "    logits = torch.matmul(student_norm, teacher_norm.t())  # (B, B)\n",
        "    logits = logits / tau\n",
        "    targets = torch.arange(logits.size(0), device=logits.device)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "    return loss\n",
        "\n",
        "# -----------------------\n",
        "# Evaluation\n",
        "# -----------------------\n",
        "def evaluate(model, dataloader, device=DEVICE):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            out = model(imgs)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# -----------------------\n",
        "# Training loop\n",
        "# -----------------------\n",
        "def train_crd(teacher, student, trainloader, testloader, num_epochs=NUM_EPOCHS, device=DEVICE):\n",
        "    teacher.eval()\n",
        "    # feature storage dicts\n",
        "    feat_t = {}\n",
        "    feat_s = {}\n",
        "\n",
        "    # register hooks\n",
        "    h_t = register_last_feature_hook(teacher, feat_t, key=\"feat\")\n",
        "    h_s = register_last_feature_hook(student, feat_s, key=\"feat\")\n",
        "\n",
        "    # avgpool for conv maps -> vector\n",
        "    avgpool = nn.AdaptiveAvgPool2d((1,1)).to(device)\n",
        "\n",
        "    # determine dims via single forward\n",
        "    with torch.no_grad():\n",
        "        dummy = torch.randn(1,3,32,32).to(device)\n",
        "        teacher(dummy)\n",
        "        t_map = feat_t[\"feat\"]  # (1, C_t, H, W)\n",
        "        t_dim = t_map.shape[1]\n",
        "        student(dummy)\n",
        "        s_map = feat_s[\"feat\"]\n",
        "        s_dim = s_map.shape[1]\n",
        "\n",
        "    # projectors\n",
        "    proj_t = ProjectionHead(t_dim, proj_dim=PROJ_DIM).to(device)\n",
        "    proj_s = ProjectionHead(s_dim, proj_dim=PROJ_DIM).to(device)\n",
        "\n",
        "    # Option: initialize proj_t from identity-ish or leave random. We'll freeze proj_t.\n",
        "    for p in proj_t.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # optimizer: student params + proj_s params\n",
        "    optim_params = list(student.parameters()) + list(proj_s.parameters())\n",
        "    optimizer = optim.SGD(optim_params, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_acc = 0.0\n",
        "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "    # Prepare CSV log\n",
        "    with open(LOG_CSV, \"w\", newline=\"\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"epoch\", \"train_loss\", \"train_ce\", \"train_crd\", \"val_acc\"])\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        student.train()\n",
        "        proj_s.train()\n",
        "        running_loss = 0.0\n",
        "        running_ce = 0.0\n",
        "        running_crd = 0.0\n",
        "        iters = 0\n",
        "        pbar = tqdm(trainloader, desc=f\"CRD Epoch {epoch}/{num_epochs}\")\n",
        "        for imgs, labels in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # teacher forward (no grad)\n",
        "            with torch.no_grad():\n",
        "                _ = teacher(imgs)\n",
        "                t_map = feat_t[\"feat\"]        # (B, C_t, H, W)\n",
        "                t_vec = avgpool(t_map).view(imgs.size(0), -1)  # (B, C_t)\n",
        "\n",
        "            # student forward (grad enabled)\n",
        "            _ = student(imgs)\n",
        "            s_map = feat_s[\"feat\"]           # (B, C_s, H, W)\n",
        "            s_vec = avgpool(s_map).view(imgs.size(0), -1)  # (B, C_s)\n",
        "\n",
        "            # project\n",
        "            with torch.no_grad():\n",
        "                t_proj = proj_t(t_vec)  # frozen teacher proj (B, PROJ_DIM)\n",
        "            s_proj = proj_s(s_vec)      # (B, PROJ_DIM)\n",
        "\n",
        "            # compute losses\n",
        "            out_logits = student(imgs)   # forward again for classifier outputs (could reuse earlier but safe)\n",
        "            loss_ce = ce_loss(out_logits, labels)\n",
        "            loss_crd = info_nce_loss(s_proj, t_proj.detach(), tau=TAU)\n",
        "            loss = loss_ce + LAMBDA_CRD * loss_crd\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # clip grads\n",
        "            torch.nn.utils.clip_grad_norm_(optim_params, CLIP_GRAD)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += float(loss.item())\n",
        "            running_ce += float(loss_ce.item())\n",
        "            running_crd += float(loss_crd.item())\n",
        "            iters += 1\n",
        "            pbar.set_postfix(train_loss=running_loss/iters, ce=running_ce/iters, crd=running_crd/iters)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # evaluate\n",
        "        val_acc = evaluate(student, testloader, device=device)\n",
        "        avg_loss = running_loss / max(1, iters)\n",
        "        avg_ce = running_ce / max(1, iters)\n",
        "        avg_crd = running_crd / max(1, iters)\n",
        "\n",
        "        # log to csv\n",
        "        with open(LOG_CSV, \"a\", newline=\"\") as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow([epoch, avg_loss, avg_ce, avg_crd, val_acc])\n",
        "\n",
        "        if epoch % PRINT_EVERY == 0:\n",
        "            print(f\"Epoch {epoch}/{num_epochs} - loss: {avg_loss:.4f} | CE: {avg_ce:.4f} | CRD: {avg_crd:.4f} | val_acc: {val_acc:.2f}%\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(student.state_dict(), STUDENT_OUT)\n",
        "            print(f\"  -> New best saved: {STUDENT_OUT} (acc {best_acc:.2f}%)\")\n",
        "\n",
        "    # remove hooks: not strictly necessary in script exit\n",
        "    try:\n",
        "        h_t.remove()\n",
        "        h_s.remove()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"CRD training finished. Best Val Acc: {:.2f}%\".format(best_acc))\n",
        "    return best_acc\n",
        "\n",
        "# -----------------------\n",
        "# Main\n",
        "# -----------------------\n",
        "def main():\n",
        "    if not os.path.exists(TEACHER_CKPT):\n",
        "        raise FileNotFoundError(f\"Teacher checkpoint not found: {TEACHER_CKPT}. Train teacher first or update TEACHER_CKPT path.\")\n",
        "\n",
        "    # build and load teacher\n",
        "    teacher = build_teacher(NUM_CLASSES).to(DEVICE)\n",
        "    teacher.load_state_dict(torch.load(TEACHER_CKPT, map_location=DEVICE))\n",
        "    teacher.eval()\n",
        "    for p in teacher.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # build student\n",
        "    student = build_student(NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "    print(\"Starting CRD training: teacher loaded, student initialized.\")\n",
        "    start = time.time()\n",
        "    best_acc = train_crd(teacher, student, trainloader, testloader, num_epochs=NUM_EPOCHS, device=DEVICE)\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"Total time: {elapsed/60.0:.2f} minutes. Best Val Acc: {best_acc:.2f}\")\n",
        "\n",
        "    final_acc = evaluate(student, testloader, device=DEVICE)\n",
        "    print(\"Final student accuracy (CRD): {:.2f}\".format(final_acc))\n",
        "    print(\"Best student saved to:\", STUDENT_OUT)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yACodACgMsGn",
        "outputId": "3197e7b6-ec4d-46e3-ca17-a26d98f5f228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CRD training: teacher loaded, student initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:53<00:00,  7.28it/s, ce=4.11, crd=3.5, train_loss=7.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - loss: 7.6112 | CE: 4.1086 | CRD: 3.5025 | val_acc: 14.85%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 14.85%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:54<00:00,  7.12it/s, ce=3.45, crd=2.58, train_loss=6.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - loss: 6.0226 | CE: 3.4470 | CRD: 2.5756 | val_acc: 22.70%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 22.70%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=3.05, crd=2.14, train_loss=5.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - loss: 5.1894 | CE: 3.0502 | CRD: 2.1392 | val_acc: 27.94%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 27.94%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=2.77, crd=1.81, train_loss=4.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - loss: 4.5777 | CE: 2.7706 | CRD: 1.8071 | val_acc: 33.57%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 33.57%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.94it/s, ce=2.54, crd=1.56, train_loss=4.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - loss: 4.1072 | CE: 2.5445 | CRD: 1.5627 | val_acc: 37.08%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 37.08%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=2.38, crd=1.38, train_loss=3.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - loss: 3.7599 | CE: 2.3790 | CRD: 1.3808 | val_acc: 40.61%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 40.61%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=2.24, crd=1.24, train_loss=3.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - loss: 3.4792 | CE: 2.2370 | CRD: 1.2422 | val_acc: 42.83%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 42.83%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=2.11, crd=1.12, train_loss=3.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - loss: 3.2278 | CE: 2.1094 | CRD: 1.1185 | val_acc: 44.67%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 44.67%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.86it/s, ce=2, crd=1.03, train_loss=3.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - loss: 3.0221 | CE: 1.9971 | CRD: 1.0250 | val_acc: 47.59%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 47.59%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.88it/s, ce=1.89, crd=0.942, train_loss=2.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - loss: 2.8310 | CE: 1.8889 | CRD: 0.9421 | val_acc: 49.53%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 49.53%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.91it/s, ce=1.79, crd=0.881, train_loss=2.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - loss: 2.6758 | CE: 1.7949 | CRD: 0.8809 | val_acc: 51.10%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 51.10%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=1.71, crd=0.818, train_loss=2.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - loss: 2.5230 | CE: 1.7055 | CRD: 0.8175 | val_acc: 52.37%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 52.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=1.63, crd=0.771, train_loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - loss: 2.4022 | CE: 1.6310 | CRD: 0.7711 | val_acc: 53.01%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 53.01%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=1.56, crd=0.729, train_loss=2.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - loss: 2.2879 | CE: 1.5584 | CRD: 0.7295 | val_acc: 53.63%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 53.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.93it/s, ce=1.49, crd=0.691, train_loss=2.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - loss: 2.1807 | CE: 1.4900 | CRD: 0.6908 | val_acc: 54.41%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 54.41%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.88it/s, ce=1.42, crd=0.656, train_loss=2.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - loss: 2.0798 | CE: 1.4234 | CRD: 0.6564 | val_acc: 55.63%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 55.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.85it/s, ce=1.35, crd=0.627, train_loss=1.97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - loss: 1.9731 | CE: 1.3466 | CRD: 0.6265 | val_acc: 56.18%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 56.18%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=1.29, crd=0.6, train_loss=1.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - loss: 1.8942 | CE: 1.2942 | CRD: 0.6000 | val_acc: 57.59%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 57.59%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.91it/s, ce=1.24, crd=0.578, train_loss=1.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - loss: 1.8145 | CE: 1.2361 | CRD: 0.5784 | val_acc: 58.28%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 58.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.94it/s, ce=1.18, crd=0.559, train_loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - loss: 1.7378 | CE: 1.1789 | CRD: 0.5589 | val_acc: 58.31%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 58.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.88it/s, ce=1.13, crd=0.538, train_loss=1.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - loss: 1.6679 | CE: 1.1301 | CRD: 0.5378 | val_acc: 58.82%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 58.82%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=1.07, crd=0.525, train_loss=1.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - loss: 1.6000 | CE: 1.0748 | CRD: 0.5252 | val_acc: 59.84%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 59.84%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.87it/s, ce=1.04, crd=0.514, train_loss=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - loss: 1.5510 | CE: 1.0373 | CRD: 0.5136 | val_acc: 59.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.95it/s, ce=0.997, crd=0.502, train_loss=1.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - loss: 1.4997 | CE: 0.9972 | CRD: 0.5024 | val_acc: 60.36%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 60.36%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.92it/s, ce=0.958, crd=0.492, train_loss=1.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - loss: 1.4500 | CE: 0.9579 | CRD: 0.4922 | val_acc: 60.38%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 60.38%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.91it/s, ce=0.928, crd=0.484, train_loss=1.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - loss: 1.4128 | CE: 0.9284 | CRD: 0.4844 | val_acc: 60.85%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 60.85%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.90it/s, ce=0.906, crd=0.48, train_loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - loss: 1.3861 | CE: 0.9063 | CRD: 0.4798 | val_acc: 61.21%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 61.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.91it/s, ce=0.888, crd=0.472, train_loss=1.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - loss: 1.3602 | CE: 0.8883 | CRD: 0.4718 | val_acc: 61.26%\n",
            "  -> New best saved: student_vgg11_CRD.pth (acc 61.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.89it/s, ce=0.88, crd=0.47, train_loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - loss: 1.3502 | CE: 0.8800 | CRD: 0.4702 | val_acc: 61.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.93it/s, ce=0.873, crd=0.47, train_loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - loss: 1.3423 | CE: 0.8728 | CRD: 0.4695 | val_acc: 61.16%\n",
            "CRD training finished. Best Val Acc: 61.26%\n",
            "Total time: 31.53 minutes. Best Val Acc: 61.26\n",
            "Final student accuracy (CRD): 61.16\n",
            "Best student saved to: student_vgg11_CRD.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Local model file (after training)\n",
        "# local_path = \"student_vgg11_CRD.pth\"\n",
        "\n",
        "# # Destination in Google Drive\n",
        "# drive_path = \"/content/drive/MyDrive/student_vgg11_CRD.pth\"\n",
        "\n",
        "# # Copy file\n",
        "# shutil.copy(local_path, drive_path)\n",
        "# print(f\"âœ… Model saved to Google Drive at: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zZ7SIJ0aAJ4",
        "outputId": "2dd9f8ce-06b0-42c3-c634-1d5a785ffcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model saved to Google Drive at: /content/drive/MyDrive/student_vgg11_CRD.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparing Probability Distributions"
      ],
      "metadata": {
        "id": "y-uYn6HYngTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Part 3: Compare Teacherâ€“Student Output Distributions (KL Divergence)\n",
        "# ==============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg11_bn, vgg11, vgg16\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Model definitions\n",
        "# --------------------------------------------------------------\n",
        "def get_vgg16_teacher(num_classes=100):\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def get_vgg11_student(num_classes=100):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def get_vgg11bn_student(num_classes=100):\n",
        "    model = vgg11_bn(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# CIFAR-100 dataloaders\n",
        "# --------------------------------------------------------------\n",
        "def get_dataloaders(batch_size=64):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                             (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "    testset = torchvision.datasets.CIFAR100(root=\"./data\", train=False,\n",
        "                                            download=True, transform=transform_test)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return testloader\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Load teacher and student models\n",
        "# --------------------------------------------------------------\n",
        "def load_models(device):\n",
        "    base_path = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content\"\n",
        "\n",
        "    teacher = get_vgg16_teacher().to(device)\n",
        "    teacher.load_state_dict(torch.load(os.path.join(base_path, \"teacher_vgg16.pth\"), map_location=device))\n",
        "    teacher.eval()\n",
        "\n",
        "    # Define students\n",
        "    students = {\n",
        "        \"Independent\": get_vgg11_student().to(device),\n",
        "        \"LogitMatching\": get_vgg11_student().to(device),\n",
        "        \"Hint\": get_vgg11_student().to(device),\n",
        "        \"DKD\": get_vgg11_student().to(device),\n",
        "        \"LabelSmoothing\": get_vgg11bn_student().to(device)\n",
        "    }\n",
        "\n",
        "    ckpts = {\n",
        "        \"Independent\": os.path.join(base_path, \"student_vgg11_independent.pth\"),\n",
        "        \"LogitMatching\": os.path.join(base_path, \"student_vgg11_LM_tuned.pth\"),\n",
        "        \"Hint\": os.path.join(base_path, \"student_vgg11_hints.pth\"),\n",
        "        \"DKD\": os.path.join(base_path, \"student_vgg11_DKD.pth\"),\n",
        "        \"LabelSmoothing\": os.path.join(base_path, \"student_vgg11_LS.pth\"),\n",
        "    }\n",
        "\n",
        "    for name, model in students.items():\n",
        "        ckpt_path = ckpts[name]\n",
        "        if os.path.exists(ckpt_path):\n",
        "            model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "            model.eval()\n",
        "            print(f\"âœ… Loaded {name} model from {ckpt_path}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ Warning: checkpoint not found for {name}: {ckpt_path}\")\n",
        "\n",
        "    print(\"âœ… All available models loaded.\")\n",
        "    return teacher, students\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# KL divergence (numerically stable)\n",
        "# --------------------------------------------------------------\n",
        "def compute_kl_divergence(p_teacher, p_student):\n",
        "    kl = F.kl_div(p_student.log(), p_teacher, reduction=\"batchmean\")\n",
        "    return kl.item()\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Compare teacher and students\n",
        "# --------------------------------------------------------------\n",
        "def compare_distributions(device, batch_size=64, temperature=4.0, num_batches=20):\n",
        "    testloader = get_dataloaders(batch_size)\n",
        "    teacher, students = load_models(device)\n",
        "\n",
        "    results = {k: [] for k in students.keys()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, _) in enumerate(tqdm(testloader, total=num_batches, desc=\"Evaluating KL Divergence\")):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "            images = images.to(device)\n",
        "            # Teacher probs (softened)\n",
        "            t_logits = teacher(images) / temperature\n",
        "            t_probs = F.softmax(t_logits, dim=1)\n",
        "\n",
        "            for name, student in students.items():\n",
        "                s_logits = student(images) / temperature\n",
        "                s_probs = F.softmax(s_logits, dim=1)\n",
        "\n",
        "                # Compute divergence between teacher & student\n",
        "                kl = compute_kl_divergence(t_probs, s_probs)\n",
        "                results[name].append(kl)\n",
        "\n",
        "    avg_kl = {name: np.mean(vals) for name, vals in results.items() if len(vals) > 0}\n",
        "\n",
        "    print(\"\\n=== ðŸ“Š Average KL Divergence: Teacher vs Students ===\")\n",
        "    for name, val in avg_kl.items():\n",
        "        print(f\"{name:15s}: {val:.6f}\")\n",
        "\n",
        "    # Save results\n",
        "    df = pd.DataFrame(list(avg_kl.items()), columns=[\"Student Model\", \"KL Divergence\"])\n",
        "    df.sort_values(\"KL Divergence\", inplace=True)\n",
        "    out_path = \"KL_results.csv\"\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"\\nðŸ“ Results saved to: {out_path}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Run\n",
        "# --------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    results_df = compare_distributions(device, batch_size=64, temperature=4.0, num_batches=20)\n",
        "    print(\"\\nâœ… KL Divergence Comparison Complete.\")\n",
        "    display(results_df)"
      ],
      "metadata": {
        "id": "mujY2aK2pAdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "50d62a14-6293-4cf8-b082-604b81d4c7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Warning: checkpoint not found for Independent: /content/drive/MyDrive/student_vgg11_independent.pth\n",
            "âœ… Loaded LogitMatching model from /content/drive/MyDrive/student_vgg11_LM_tuned.pth\n",
            "âš ï¸ Warning: checkpoint not found for Hint: /content/drive/MyDrive/student_vgg11_hints.pth\n",
            "âœ… Loaded DKD model from /content/drive/MyDrive/student_vgg11_DKD.pth\n",
            "âš ï¸ Warning: checkpoint not found for LabelSmoothing: /content/drive/MyDrive/student_vgg11_LS.pth\n",
            "âœ… All available models loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating KL Divergence: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ðŸ“Š Average KL Divergence: Teacher vs Students ===\n",
            "Independent    : 0.469650\n",
            "LogitMatching  : 0.061759\n",
            "Hint           : 0.469483\n",
            "DKD            : 0.080693\n",
            "LabelSmoothing : 0.486313\n",
            "\n",
            "ðŸ“ Results saved to: KL_results.csv\n",
            "\n",
            "âœ… KL Divergence Comparison Complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Student Model  KL Divergence\n",
              "1   LogitMatching       0.061759\n",
              "3             DKD       0.080693\n",
              "2            Hint       0.469483\n",
              "0     Independent       0.469650\n",
              "4  LabelSmoothing       0.486313"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65020a6b-aecb-4c32-88b1-f7eb98636236\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Student Model</th>\n",
              "      <th>KL Divergence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogitMatching</td>\n",
              "      <td>0.061759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DKD</td>\n",
              "      <td>0.080693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hint</td>\n",
              "      <td>0.469483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Independent</td>\n",
              "      <td>0.469650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LabelSmoothing</td>\n",
              "      <td>0.486313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65020a6b-aecb-4c32-88b1-f7eb98636236')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65020a6b-aecb-4c32-88b1-f7eb98636236 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65020a6b-aecb-4c32-88b1-f7eb98636236');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ca54556-ebde-498d-938d-5eabe6553b83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ca54556-ebde-498d-938d-5eabe6553b83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ca54556-ebde-498d-938d-5eabe6553b83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0aa7959c-229c-4bf1-920f-40a8d46d0a4d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0aa7959c-229c-4bf1-920f-40a8d46d0a4d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Student Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"DKD\",\n          \"LabelSmoothing\",\n          \"Hint\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KL Divergence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22144448385917287,\n        \"min\": 0.06175865139812231,\n        \"max\": 0.48631261438131335,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.08069294169545174,\n          0.48631261438131335,\n          0.46948294937610624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Examining Localization Knowledge Transfer"
      ],
      "metadata": {
        "id": "WFAvAt-YflmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UQ74JwwzGwI",
        "outputId": "2ca37056-f039-4ddf-fc3a-54978e8dedc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.5.5.tar.gz (7.8 MB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/7.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/7.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from grad-cam) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (0.23.0+cu126)\n",
            "Collecting ttach (from grad-cam)\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.3)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.5.5-py3-none-any.whl size=44284 sha256=80d311dd2a778b103dc00cdf2cd771ba362b3a4f303fcf777b21125ddac29a52\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/3b/09/2afc520f3d69bc26ae6bd87416759c820a3f7d05c1a077bbf6\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.5.5 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradcam_kd_compare.py\n",
        "# Run in Colab or locally. Requires: torch, torchvision, pytorch-grad-cam, matplotlib, pandas, tqdm\n",
        "# Installs: pip install grad-cam\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg11, vgg11_bn, vgg16\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "N_IMAGES = 20               # number of query images to analyze\n",
        "OUTPUT_DIR = \"gradcam_results\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Candidate checkpoint filenames (will search in drive then cwd)\n",
        "CKPT_NAMES = {\n",
        "    \"Teacher\": \"teacher_vgg16.pth\",\n",
        "    \"SI\": \"student_vgg11_SI.pth\",\n",
        "    \"LM\": \"student_vgg11_LM_tuned.pth\",\n",
        "    \"Hints\": \"student_vgg11_hints.pth\",\n",
        "    \"DKD\": \"student_vgg11_DKD.pth\",\n",
        "    \"CRD\": \"student_vgg11_CRD.pth\",   # optional\n",
        "    \"LS\": \"student_vgg11_LS.pth\"      # optional\n",
        "}\n",
        "\n",
        "# CIFAR-100 normalization used during training\n",
        "MEAN = (0.5071, 0.4867, 0.4408)\n",
        "STD  = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "# IoU top fraction\n",
        "TOPK_FRAC = 0.20\n",
        "\n",
        "# Input size for Grad-CAM overlays (we use 224 to work with VGG models)\n",
        "INP_SIZE = 224\n",
        "\n",
        "# ---------------- Helpers ----------------\n",
        "def find_checkpoint(filename):\n",
        "    # prefer Google Drive path if mounted, else current dir\n",
        "    drive_path = \"/content/drive/MyDrive\"\n",
        "    candidates = []\n",
        "    if os.path.exists(drive_path):\n",
        "        candidates.append(os.path.join(drive_path, filename))\n",
        "    candidates.append(filename)\n",
        "    for p in candidates:\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def build_teacher(num_classes=100):\n",
        "    m = vgg16(weights=None)\n",
        "    m.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return m\n",
        "\n",
        "def build_student(num_classes=100, bn=False):\n",
        "    if bn:\n",
        "        m = vgg11_bn(weights=None)\n",
        "    else:\n",
        "        m = vgg11(weights=None)\n",
        "    m.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return m\n",
        "\n",
        "def find_last_conv_layer(model):\n",
        "    last_conv = None\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            last_conv = m\n",
        "    if last_conv is None:\n",
        "        raise ValueError(\"No Conv2d found in model\")\n",
        "    return last_conv\n",
        "\n",
        "def normalize_map(cam):\n",
        "    cam = np.array(cam, dtype=np.float32)\n",
        "    cam = cam - cam.min()\n",
        "    if cam.max() > 0:\n",
        "        cam = cam / (cam.max() + 1e-12)\n",
        "    return cam\n",
        "\n",
        "def pearson_corr(a, b):\n",
        "    a = a.flatten(); b = b.flatten()\n",
        "    a = (a - a.mean()) / (a.std() + 1e-12)\n",
        "    b = (b - b.mean()) / (b.std() + 1e-12)\n",
        "    return float(np.mean(a * b))\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    a = a.flatten(); b = b.flatten()\n",
        "    an = np.linalg.norm(a); bn = np.linalg.norm(b)\n",
        "    if an < 1e-12 or bn < 1e-12:\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / (an * bn))\n",
        "\n",
        "def iou_topk(a, b, frac=TOPK_FRAC):\n",
        "    flat_a = a.flatten(); flat_b = b.flatten()\n",
        "    k = max(1, int(len(flat_a) * frac))\n",
        "    top_a = np.argpartition(-flat_a, k-1)[:k]\n",
        "    top_b = np.argpartition(-flat_b, k-1)[:k]\n",
        "    set_a = set(top_a.tolist()); set_b = set(top_b.tolist())\n",
        "    inter = len(set_a & set_b); union = len(set_a | set_b)\n",
        "    if union == 0:\n",
        "        return 0.0\n",
        "    return inter / union\n",
        "\n",
        "# ---------------- Prepare dataset ----------------\n",
        "transform_vis = transforms.Compose([\n",
        "    transforms.Resize(INP_SIZE),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "transform_input = transforms.Compose([\n",
        "    transforms.Resize(INP_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "test_vis = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform_vis)\n",
        "test_input = torchvision.datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=transform_input)\n",
        "\n",
        "# select indices: first N_IMAGES by default (you can change)\n",
        "selected_indices = list(range(N_IMAGES))\n",
        "selected_vis = [test_vis[i][0] for i in selected_indices]\n",
        "selected_labels = [test_input[i][1] for i in selected_indices]  # ground truth if needed\n",
        "\n",
        "# ---------------- Load models ----------------\n",
        "print(\"Loading models (searching in drive then cwd)...\")\n",
        "models = {}\n",
        "for role, fname in CKPT_NAMES.items():\n",
        "    path = find_checkpoint(fname)\n",
        "    if path is None:\n",
        "        print(f\"  - {role}: checkpoint not found ({fname}) â€” skipping\")\n",
        "        continue\n",
        "    if role == \"Teacher\":\n",
        "        model = build_teacher().to(DEVICE)\n",
        "    else:\n",
        "        # label smoothing model used vgg11_bn in some runs\n",
        "        if role == \"LS\":\n",
        "            model = build_student(bn=True).to(DEVICE)\n",
        "        else:\n",
        "            model = build_student().to(DEVICE)\n",
        "    try:\n",
        "        state = torch.load(path, map_location=DEVICE)\n",
        "        model.load_state_dict(state)\n",
        "        model.eval()\n",
        "        models[role] = model\n",
        "        print(f\"  - {role}: loaded from {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - {role}: failed to load {path}: {e}\")\n",
        "\n",
        "if \"Teacher\" not in models:\n",
        "    raise RuntimeError(\"Teacher checkpoint is required. Place teacher_vgg16.pth in drive or cwd.\")\n",
        "\n",
        "print(f\"Models available for Grad-CAM: {list(models.keys())}\")\n",
        "\n",
        "# ---------------- Prepare CAM objects ----------------\n",
        "cams = {}\n",
        "for name, m in models.items():\n",
        "    layer = find_last_conv_layer(m)\n",
        "    # Updated: Use the device directly instead of the use_cuda argument\n",
        "    cam_obj = GradCAM(model=m, target_layers=[layer])\n",
        "    cams[name] = cam_obj\n",
        "\n",
        "# ---------------- Compute GradCAMs & metrics ----------------\n",
        "rows = []\n",
        "for idx in range(len(selected_vis)):\n",
        "    vis_img = selected_vis[idx]  # tensor (3,H,W) in [0,1]\n",
        "    np_img = np.transpose(vis_img.numpy(), (1,2,0))\n",
        "    np_img = np.clip(np_img, 0, 1)\n",
        "\n",
        "    input_tensor = preprocess_image(np_img, mean=MEAN, std=STD).to(DEVICE)\n",
        "\n",
        "    # Teacher prediction / target class\n",
        "    with torch.no_grad():\n",
        "        t_logits = models[\"Teacher\"](input_tensor)\n",
        "        t_pred = int(torch.argmax(t_logits, dim=1).item())\n",
        "\n",
        "    target = [ClassifierOutputTarget(t_pred)]\n",
        "    teacher_cam = cams[\"Teacher\"](input_tensor=input_tensor, targets=target, eigen_smooth=False, aug_smooth=False)\n",
        "    teacher_map = normalize_map(teacher_cam[0])\n",
        "\n",
        "    # make output dir for image\n",
        "    out_dir = os.path.join(OUTPUT_DIR, f\"img_{idx:03d}\")\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Save teacher overlay\n",
        "    teacher_overlay = show_cam_on_image(np_img, teacher_map, use_rgb=True)\n",
        "    Image.fromarray(teacher_overlay).save(os.path.join(out_dir, \"teacher_overlay.png\"))\n",
        "    np.save(os.path.join(out_dir, \"teacher_map.npy\"), teacher_map)\n",
        "\n",
        "    row = {\"image_idx\": idx, \"teacher_pred\": t_pred}\n",
        "\n",
        "    # For each student model compute cam and metrics vs teacher_map\n",
        "    for name, cam_obj in cams.items():\n",
        "        if name == \"Teacher\":\n",
        "            continue\n",
        "        try:\n",
        "            student_cam = cam_obj(input_tensor=input_tensor, targets=target, eigen_smooth=False, aug_smooth=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: CAM failed for {name} on img {idx}: {e}\")\n",
        "            student_map = np.zeros_like(teacher_map)\n",
        "        else:\n",
        "            student_map = normalize_map(student_cam[0])\n",
        "\n",
        "        # metrics\n",
        "        p_corr = pearson_corr(teacher_map, student_map)\n",
        "        c_sim = cosine_sim(teacher_map, student_map)\n",
        "        iou = iou_topk(teacher_map, student_map, frac=TOPK_FRAC)\n",
        "\n",
        "        row[f\"{name}_pearson\"] = p_corr\n",
        "        row[f\"{name}_cosine\"]  = c_sim\n",
        "        row[f\"{name}_iou\"]     = iou\n",
        "\n",
        "        # save overlay and map\n",
        "        overlay = show_cam_on_image(np_img, student_map, use_rgb=True)\n",
        "        Image.fromarray(overlay).save(os.path.join(out_dir, f\"{name}_overlay.png\"))\n",
        "        np.save(os.path.join(out_dir, f\"{name}_map.npy\"), student_map)\n",
        "\n",
        "    rows.append(row)\n",
        "    print(f\"Processed image {idx+1}/{len(selected_vis)}\")\n",
        "\n",
        "# ---------------- Save CSV of metrics ----------------\n",
        "df = pd.DataFrame(rows)\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"gradcam_similarity_metrics.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Saved metrics to:\", csv_path)\n",
        "\n",
        "# ---------------- Aggregate & plot ----------------\n",
        "# compute mean metrics per model\n",
        "student_names = [n for n in cams.keys() if n != \"Teacher\"]\n",
        "summary = {}\n",
        "for name in student_names:\n",
        "    pear = df[f\"{name}_pearson\"].mean()\n",
        "    cos  = df[f\"{name}_cosine\"].mean()\n",
        "    iou  = df[f\"{name}_iou\"].mean()\n",
        "    summary[name] = {\"pearson\": pear, \"cosine\": cos, \"iou\": iou}\n",
        "summary_df = pd.DataFrame.from_dict(summary, orient=\"index\")\n",
        "summary_df = summary_df[[\"pearson\", \"cosine\", \"iou\"]]\n",
        "\n",
        "print(\"\\nMean Grad-CAM similarity metrics (Teacher vs Student):\\n\", summary_df)\n",
        "\n",
        "# save summary csv\n",
        "summary_csv = os.path.join(OUTPUT_DIR, \"gradcam_similarity_summary.csv\")\n",
        "summary_df.to_csv(summary_csv)\n",
        "print(\"Saved summary CSV to:\", summary_csv)\n",
        "\n",
        "# plot bar charts for each metric\n",
        "plt.figure(figsize=(10,5))\n",
        "summary_df[\"pearson\"].plot(kind=\"bar\")\n",
        "plt.title(\"Mean Pearson Correlation (Teacher vs Student CAM)\")\n",
        "plt.ylabel(\"Pearson\")\n",
        "plt.ylim(-1,1)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"pearson_summary.png\"))\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "summary_df[\"cosine\"].plot(kind=\"bar\")\n",
        "plt.title(\"Mean Cosine Similarity (Teacher vs Student CAM)\")\n",
        "plt.ylabel(\"Cosine\")\n",
        "plt.ylim(0,1)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"cosine_summary.png\"))\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "summary_df[\"iou\"].plot(kind=\"bar\")\n",
        "plt.title(f\"Mean IoU (top {int(TOPK_FRAC*100)}%) (Teacher vs Student CAM)\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.ylim(0,1)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"iou_summary.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved summary plots in\", OUTPUT_DIR)\n",
        "\n",
        "# ---------------- Optionally create montage per image ----------------\n",
        "# saves a side-by-side composite for quick inspection\n",
        "for idx in range(len(selected_vis)):\n",
        "    out_dir = os.path.join(OUTPUT_DIR, f\"img_{idx:03d}\")\n",
        "    imgs = []\n",
        "    # teacher first\n",
        "    teacher_path = os.path.join(out_dir, \"teacher_overlay.png\")\n",
        "    if os.path.exists(teacher_path):\n",
        "        imgs.append(Image.open(teacher_path))\n",
        "    student_names = [n for n in CKPT_NAMES.keys() if n != \"Teacher\" and n in models.keys()] # Use available models\n",
        "    for name in student_names:\n",
        "        p = os.path.join(out_dir, f\"{name}_overlay.png\")\n",
        "        if os.path.exists(p):\n",
        "            imgs.append(Image.open(p))\n",
        "    # create horizontal montage\n",
        "    if imgs: # check if there are any images to montage\n",
        "        widths, heights = zip(*(i.size for i in imgs))\n",
        "        total_w = sum(widths)\n",
        "        max_h = max(heights)\n",
        "        montage = Image.new('RGB', (total_w, max_h))\n",
        "        x = 0\n",
        "        for im in imgs:\n",
        "            montage.paste(im, (x, 0))\n",
        "            x += im.size[0]\n",
        "        montage.save(os.path.join(out_dir, \"montage.png\"))\n",
        "    else:\n",
        "        print(f\"No images found to create montage for image index {idx}\")\n",
        "\n",
        "print(\"Montages saved. All done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA3QLH4TIGnk",
        "outputId": "2c8dfbba-e247-4fae-95d5-db084ce3d150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models (searching in drive then cwd)...\n",
            "  - Teacher: loaded from /content/drive/MyDrive/teacher_vgg16.pth\n",
            "  - SI: loaded from /content/drive/MyDrive/student_vgg11_SI.pth\n",
            "  - LM: loaded from /content/drive/MyDrive/student_vgg11_LM_tuned.pth\n",
            "  - Hints: checkpoint not found (student_vgg11_hints.pth) â€” skipping\n",
            "  - DKD: loaded from /content/drive/MyDrive/student_vgg11_DKD.pth\n",
            "  - CRD: loaded from /content/drive/MyDrive/student_vgg11_CRD.pth\n",
            "  - LS: checkpoint not found (student_vgg11_LS.pth) â€” skipping\n",
            "Models available for Grad-CAM: ['Teacher', 'SI', 'LM', 'DKD', 'CRD']\n",
            "Processed image 1/20\n",
            "Processed image 2/20\n",
            "Processed image 3/20\n",
            "Processed image 4/20\n",
            "Processed image 5/20\n",
            "Processed image 6/20\n",
            "Processed image 7/20\n",
            "Processed image 8/20\n",
            "Processed image 9/20\n",
            "Processed image 10/20\n",
            "Processed image 11/20\n",
            "Processed image 12/20\n",
            "Processed image 13/20\n",
            "Processed image 14/20\n",
            "Processed image 15/20\n",
            "Processed image 16/20\n",
            "Processed image 17/20\n",
            "Processed image 18/20\n",
            "Processed image 19/20\n",
            "Processed image 20/20\n",
            "Saved metrics to: gradcam_results/gradcam_similarity_metrics.csv\n",
            "\n",
            "Mean Grad-CAM similarity metrics (Teacher vs Student):\n",
            "       pearson    cosine       iou\n",
            "SI   0.110614  0.467609  0.175526\n",
            "LM   0.060328  0.614667  0.139875\n",
            "DKD  0.036209  0.656519  0.138029\n",
            "CRD -0.002989  0.633637  0.137794\n",
            "Saved summary CSV to: gradcam_results/gradcam_similarity_summary.csv\n",
            "Saved summary plots in gradcam_results\n",
            "Montages saved. All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Checking for Color Invariance with CRD"
      ],
      "metadata": {
        "id": "JnDps9foft3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crd_color_invariance.py\n",
        "# Part 5: Check Color Invariance with CRD\n",
        "# 1) Finetune teacher with color jitter augmentations\n",
        "# 2) Use that teacher to train a CRD student (student uses regular augmentations)\n",
        "# 3) Evaluate teacher and student on original and color-jittered test sets\n",
        "#\n",
        "# Requirements: torch, torchvision, tqdm, numpy, pandas\n",
        "# Place teacher_vgg16.pth in working dir or /content/drive/MyDrive/\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import csv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import vgg16, vgg11\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ---------------------------\n",
        "# Config / Hyperparams\n",
        "# ---------------------------\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BASE_PATH = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \".\"\n",
        "\n",
        "# Files (existing and outputs)\n",
        "TEACHER_CKPT = os.path.join(BASE_PATH, \"teacher_vgg16.pth\")            # required (existing trained teacher)\n",
        "TEACHER_COLOR_CKPT = os.path.join(BASE_PATH, \"teacher_vgg16_colorfinetune.pth\")\n",
        "STUDENT_CRD_OUT = os.path.join(BASE_PATH, \"student_vgg11_CRD_colorteacher.pth\")\n",
        "LOG_CSV = os.path.join(BASE_PATH, \"crd_color_invariance_log.csv\")\n",
        "\n",
        "# Training params\n",
        "FINETUNE_TEACHER = True              # whether to finetune teacher with color augmentations\n",
        "FINETUNE_EPOCHS = 8                  # short finetune (adjust if you want)\n",
        "FINETUNE_LR = 0.01\n",
        "\n",
        "DO_TRAIN_CRD = True                  # whether to train student via CRD using the color teacher\n",
        "CRD_EPOCHS = 30\n",
        "BATCH_SIZE = 128\n",
        "NUM_WORKERS = 2\n",
        "LR_CRD = 0.01\n",
        "WEIGHT_DECAY = 5e-4\n",
        "MOMENTUM = 0.9\n",
        "CLIP_GRAD = 5.0\n",
        "\n",
        "# CRD hyperparams\n",
        "PROJ_DIM = 256\n",
        "TAU = 0.07\n",
        "LAMBDA_CRD = 1.0\n",
        "\n",
        "NUM_CLASSES = 100\n",
        "SEED = 42\n",
        "\n",
        "# ---------------------------\n",
        "# Reproducibility\n",
        "# ---------------------------\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# ---------------------------\n",
        "# Model builders\n",
        "# ---------------------------\n",
        "def build_teacher(num_classes=NUM_CLASSES):\n",
        "    model = vgg16(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "def build_student(num_classes=NUM_CLASSES):\n",
        "    model = vgg11(weights=None)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Datasets & transforms\n",
        "# ---------------------------\n",
        "# Base normalization (same as your previous experiments)\n",
        "MEAN = (0.5071, 0.4867, 0.4408)\n",
        "STD  = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "# Teacher finetune augmentation: strong color jitter + random grayscale\n",
        "teacher_train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.1),\n",
        "    transforms.RandomApply([transforms.RandomGrayscale(p=0.2)], p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "# Student training uses regular augmentations (we do NOT want to explicitly teach student color invariance)\n",
        "student_train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "# Test transforms: original (no jitter) and color-jittered test\n",
        "test_transform_orig = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "# Color-jittered test uses same color augment + to-tensor + normalize (deterministic variation per sample)\n",
        "test_transform_color = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.1),\n",
        "    transforms.RandomApply([transforms.RandomGrayscale(p=0.2)], p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "# Data loaders\n",
        "def get_dataloaders(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, for_teacher=False):\n",
        "    if for_teacher:\n",
        "        train_transform = teacher_train_transform\n",
        "    else:\n",
        "        train_transform = student_train_transform\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    testset_orig = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform_orig)\n",
        "    testloader_orig = DataLoader(testset_orig, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    testset_color = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform_color)\n",
        "    testloader_color = DataLoader(testset_color, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    return trainloader, testloader_orig, testloader_color\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities: evaluate\n",
        "# ---------------------------\n",
        "def evaluate_model(model, dataloader, device=DEVICE):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            out = model(imgs)\n",
        "            preds = out.argmax(dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# ---------------------------\n",
        "# Finetune teacher with color augmentation\n",
        "# ---------------------------\n",
        "def finetune_teacher_color(teacher_ckpt, out_ckpt, epochs=FINETUNE_EPOCHS, lr=FINETUNE_LR):\n",
        "    if not os.path.exists(teacher_ckpt):\n",
        "        raise FileNotFoundError(f\"Teacher checkpoint not found at {teacher_ckpt}. Provide pretrained teacher first.\")\n",
        "\n",
        "    # load teacher\n",
        "    teacher = build_teacher().to(DEVICE)\n",
        "    teacher.load_state_dict(torch.load(teacher_ckpt, map_location=DEVICE))\n",
        "    print(\"Loaded teacher from\", teacher_ckpt)\n",
        "\n",
        "    # freeze most layers? here we finetune entire model (small lr)\n",
        "    for p in teacher.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "    trainloader, test_orig, test_color = get_dataloaders(for_teacher=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(teacher.parameters(), lr=lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_acc_color = 0.0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        teacher.train()\n",
        "        running_loss = 0.0\n",
        "        pbar = tqdm(trainloader, desc=f\"Finetune Teacher (color) Epoch {epoch}/{epochs}\")\n",
        "        for imgs, labels in pbar:\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            out = teacher(imgs)\n",
        "            loss = criterion(out, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += float(loss.item())\n",
        "            pbar.set_postfix(avg_loss=running_loss/(len(pbar)+1))\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluate on color test set to measure color invariance of teacher\n",
        "        teacher.eval()\n",
        "        acc_color = evaluate_model(teacher, test_color)\n",
        "        acc_orig = evaluate_model(teacher, test_orig)\n",
        "        print(f\"Epoch {epoch}: Teacher val orig: {acc_orig:.2f}% | val color: {acc_color:.2f}%\")\n",
        "        if acc_color > best_acc_color:\n",
        "            best_acc_color = acc_color\n",
        "            torch.save(teacher.state_dict(), out_ckpt)\n",
        "            print(f\"  -> Saved color-finetuned teacher to {out_ckpt} (val_color {best_acc_color:.2f}%)\")\n",
        "\n",
        "    print(\"Teacher finetune complete. Best color test acc:\", best_acc_color)\n",
        "    return out_ckpt\n",
        "\n",
        "# ---------------------------\n",
        "# CRD training (student uses regular augmentations)\n",
        "# ---------------------------\n",
        "# We'll reuse the CRD implementation with last conv features + projection heads\n",
        "def register_last_feature_hook(model, storage_dict, key=\"feat\"):\n",
        "    last_conv = None\n",
        "    for m in model.features:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            last_conv = m\n",
        "    if last_conv is None:\n",
        "        raise RuntimeError(\"No Conv2d found in model.features\")\n",
        "    handle = last_conv.register_forward_hook(lambda module, inp, out: storage_dict.update({key: out}))\n",
        "    return handle\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim, proj_dim=PROJ_DIM):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, in_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_dim, proj_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def info_nce_loss(student_proj, teacher_proj, tau=TAU):\n",
        "    student_norm = F.normalize(student_proj, dim=1)\n",
        "    teacher_norm = F.normalize(teacher_proj, dim=1)\n",
        "    logits = torch.matmul(student_norm, teacher_norm.t()) / tau\n",
        "    targets = torch.arange(logits.size(0), device=logits.device)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "    return loss\n",
        "\n",
        "def train_crd_with_color_teacher(teacher_ckpt, out_student_ckpt, epochs=CRD_EPOCHS):\n",
        "    # load teacher (color finetuned)\n",
        "    if not os.path.exists(teacher_ckpt):\n",
        "        raise FileNotFoundError(f\"Color finetuned teacher not found at {teacher_ckpt}. Run finetune first.\")\n",
        "    teacher = build_teacher().to(DEVICE)\n",
        "    teacher.load_state_dict(torch.load(teacher_ckpt, map_location=DEVICE))\n",
        "    teacher.eval()\n",
        "    for p in teacher.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    student = build_student().to(DEVICE)\n",
        "\n",
        "    feat_t = {}\n",
        "    feat_s = {}\n",
        "    h_t = register_last_feature_hook(teacher, feat_t, key=\"feat\")\n",
        "    h_s = register_last_feature_hook(student, feat_s, key=\"feat\")\n",
        "    avgpool = nn.AdaptiveAvgPool2d((1,1)).to(DEVICE)\n",
        "\n",
        "    # single forward to get dims\n",
        "    with torch.no_grad():\n",
        "        dummy = torch.randn(1,3,32,32).to(DEVICE)\n",
        "        teacher(dummy)\n",
        "        t_map = feat_t[\"feat\"]; t_dim = t_map.shape[1]\n",
        "        student(dummy)\n",
        "        s_map = feat_s[\"feat\"]; s_dim = s_map.shape[1]\n",
        "\n",
        "    proj_t = ProjectionHead(t_dim, proj_dim=PROJ_DIM).to(DEVICE)\n",
        "    proj_s = ProjectionHead(s_dim, proj_dim=PROJ_DIM).to(DEVICE)\n",
        "    # freeze teacher proj (treat teacher projections as anchors)\n",
        "    for p in proj_t.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # optimizer for student + proj_s\n",
        "    optimizer = optim.SGD(list(student.parameters()) + list(proj_s.parameters()), lr=LR_CRD, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    trainloader, test_orig, test_color = get_dataloaders()   # student train uses regular augmentations\n",
        "\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    best_val_color = 0.0\n",
        "    # create log CSV header\n",
        "    with open(LOG_CSV, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"epoch\", \"train_loss\", \"train_ce\", \"train_crd\", \"val_orig_acc\", \"val_color_acc\"])\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        student.train()\n",
        "        proj_s.train()\n",
        "        running_loss = 0.0\n",
        "        running_ce = 0.0\n",
        "        running_crd = 0.0\n",
        "        iters = 0\n",
        "        pbar = tqdm(trainloader, desc=f\"CRD student training epoch {epoch}/{epochs}\")\n",
        "        for imgs, labels in pbar:\n",
        "            imgs = imgs.to(DEVICE); labels = labels.to(DEVICE)\n",
        "\n",
        "            # teacher forward (no grad)\n",
        "            with torch.no_grad():\n",
        "                _ = teacher(imgs)\n",
        "                t_map = feat_t[\"feat\"]\n",
        "                t_vec = avgpool(t_map).view(imgs.size(0), -1)\n",
        "\n",
        "            # student forward\n",
        "            _ = student(imgs)\n",
        "            s_map = feat_s[\"feat\"]\n",
        "            s_vec = avgpool(s_map).view(imgs.size(0), -1)\n",
        "\n",
        "            # projections\n",
        "            with torch.no_grad():\n",
        "                t_proj = proj_t(t_vec)\n",
        "            s_proj = proj_s(s_vec)\n",
        "\n",
        "            # losses\n",
        "            logits = student(imgs)\n",
        "            loss_ce = ce(logits, labels)\n",
        "            loss_crd = info_nce_loss(s_proj, t_proj.detach(), tau=TAU)\n",
        "            loss = loss_ce + LAMBDA_CRD * loss_crd\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(list(student.parameters()) + list(proj_s.parameters()), CLIP_GRAD)\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += float(loss.item())\n",
        "            running_ce += float(loss_ce.item())\n",
        "            running_crd += float(loss_crd.item())\n",
        "            iters += 1\n",
        "            pbar.set_postfix(avg_loss=running_loss/iters, ce=running_ce/iters, crd=running_crd/iters)\n",
        "        scheduler.step()\n",
        "\n",
        "        # evaluate on both original & color test sets\n",
        "        val_orig_acc = evaluate_model(student, test_orig, device=DEVICE)\n",
        "        val_color_acc = evaluate_model(student, test_color, device=DEVICE)\n",
        "        avg_loss = running_loss / max(1, iters)\n",
        "        avg_ce = running_ce / max(1, iters)\n",
        "        avg_crd = running_crd / max(1, iters)\n",
        "\n",
        "        # log\n",
        "        with open(LOG_CSV, \"a\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch, avg_loss, avg_ce, avg_crd, val_orig_acc, val_color_acc])\n",
        "\n",
        "        print(f\"Epoch {epoch}: val_orig: {val_orig_acc:.2f}% | val_color: {val_color_acc:.2f}%\")\n",
        "\n",
        "        if val_color_acc > best_val_color:\n",
        "            best_val_color = val_color_acc\n",
        "            torch.save(student.state_dict(), out_student_ckpt)\n",
        "            print(f\"  -> Saved best student to {out_student_ckpt} (val_color {best_val_color:.2f}%)\")\n",
        "\n",
        "    # cleanup hooks\n",
        "    try:\n",
        "        h_t.remove(); h_s.remove()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    print(\"CRD training complete. best color-val:\", best_val_color)\n",
        "    return out_student_ckpt\n",
        "\n",
        "# ---------------------------\n",
        "# Main pipeline\n",
        "# ---------------------------\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step A: finetune teacher with color augmentation\n",
        "    if FINETUNE_TEACHER:\n",
        "        print(\"=== Step A: Color-finetune teacher (may be quick; adjust epochs) ===\")\n",
        "        finetune_teacher_color(TEACHER_CKPT, TEACHER_COLOR_CKPT, epochs=FINETUNE_EPOCHS, lr=FINETUNE_LR)\n",
        "        color_teacher_ckpt = TEACHER_COLOR_CKPT\n",
        "    else:\n",
        "        color_teacher_ckpt = TEACHER_COLOR_CKPT if os.path.exists(TEACHER_COLOR_CKPT) else TEACHER_CKPT\n",
        "\n",
        "    # Step B: Train CRD student using color-finetuned teacher (teacher frozen)\n",
        "    if DO_TRAIN_CRD:\n",
        "        print(\"=== Step B: Train CRD student using color-finetuned teacher ===\")\n",
        "        train_crd_with_color_teacher(color_teacher_ckpt, STUDENT_CRD_OUT, epochs=CRD_EPOCHS)\n",
        "    else:\n",
        "        print(\"Skipping CRD training (DO_TRAIN_CRD=False)\")\n",
        "\n",
        "    # Step C: Evaluate teacher and student on original & color test sets\n",
        "    print(\"=== Step C: Final evaluation summary ===\")\n",
        "    # load test loaders\n",
        "    _, test_orig, test_color = get_dataloaders(for_teacher=False)\n",
        "\n",
        "    # teacher eval\n",
        "    teacher = build_teacher().to(DEVICE)\n",
        "    teacher.load_state_dict(torch.load(color_teacher_ckpt, map_location=DEVICE))\n",
        "    teacher.eval()\n",
        "    t_orig_acc = evaluate_model(teacher, test_orig)\n",
        "    t_color_acc = evaluate_model(teacher, test_color)\n",
        "    print(f\"Teacher (color-finetuned) - Orig test acc: {t_orig_acc:.2f}% | Color test acc: {t_color_acc:.2f}%\")\n",
        "\n",
        "    # student eval (load best if exists)\n",
        "    if os.path.exists(STUDENT_CRD_OUT):\n",
        "        student = build_student().to(DEVICE)\n",
        "        student.load_state_dict(torch.load(STUDENT_CRD_OUT, map_location=DEVICE))\n",
        "        student.eval()\n",
        "        s_orig_acc = evaluate_model(student, test_orig)\n",
        "        s_color_acc = evaluate_model(student, test_color)\n",
        "        print(f\"Student (CRD from color-teacher) - Orig test acc: {s_orig_acc:.2f}% | Color test acc: {s_color_acc:.2f}%\")\n",
        "    else:\n",
        "        print(\"No CRD student checkpoint found at\", STUDENT_CRD_OUT)\n",
        "\n",
        "    elapsed = (time.time() - start_time) / 60.0\n",
        "    print(f\"Total time (minutes): {elapsed:.2f}\")\n",
        "    print(\"Logs saved to:\", LOG_CSV)\n",
        "    print(\"Outputs saved to:\", TEACHER_COLOR_CKPT, STUDENT_CRD_OUT)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgQ9JTtefzb0",
        "outputId": "cc58e924-4cae-46c0-a9ed-6afdaa99beac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Step A: Color-finetune teacher (may be quick; adjust epochs) ===\n",
            "Loaded teacher from /content/drive/MyDrive/teacher_vgg16.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 1/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:50<00:00,  7.73it/s, avg_loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Teacher val orig: 50.95% | val color: 48.57%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 48.57%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 2/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:54<00:00,  7.18it/s, avg_loss=1.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Teacher val orig: 54.50% | val color: 51.90%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 51.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 3/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:03<00:00,  6.19it/s, avg_loss=1.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Teacher val orig: 58.39% | val color: 55.32%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 55.32%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 4/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:04<00:00,  6.11it/s, avg_loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Teacher val orig: 61.68% | val color: 58.66%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 58.66%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 5/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:02<00:00,  6.26it/s, avg_loss=1.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Teacher val orig: 63.90% | val color: 60.97%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 60.97%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 6/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:02<00:00,  6.26it/s, avg_loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Teacher val orig: 65.80% | val color: 62.92%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 62.92%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 7/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:03<00:00,  6.11it/s, avg_loss=0.995]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Teacher val orig: 67.13% | val color: 64.28%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 64.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finetune Teacher (color) Epoch 8/8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [01:02<00:00,  6.22it/s, avg_loss=0.905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Teacher val orig: 68.29% | val color: 65.20%\n",
            "  -> Saved color-finetuned teacher to /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth (val_color 65.20%)\n",
            "Teacher finetune complete. Best color test acc: 65.2\n",
            "=== Step B: Train CRD student using color-finetuned teacher ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.86it/s, avg_loss=7.88, ce=4.11, crd=3.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: val_orig: 12.49% | val_color: 8.58%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 8.58%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.86it/s, avg_loss=6.46, ce=3.45, crd=3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: val_orig: 23.77% | val_color: 14.21%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 14.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.82it/s, avg_loss=5.64, ce=3.05, crd=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: val_orig: 26.58% | val_color: 17.49%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 17.49%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=5.06, ce=2.78, crd=2.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: val_orig: 34.98% | val_color: 24.22%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 24.22%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=4.58, ce=2.55, crd=2.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: val_orig: 36.96% | val_color: 24.52%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 24.52%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.82it/s, avg_loss=4.22, ce=2.38, crd=1.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: val_orig: 40.71% | val_color: 28.05%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 28.05%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.80it/s, avg_loss=3.91, ce=2.23, crd=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: val_orig: 41.86% | val_color: 30.81%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 30.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=3.65, ce=2.1, crd=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: val_orig: 43.20% | val_color: 30.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.90it/s, avg_loss=3.42, ce=1.98, crd=1.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: val_orig: 47.92% | val_color: 35.33%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 35.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=3.21, ce=1.86, crd=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: val_orig: 49.72% | val_color: 35.89%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 35.89%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.80it/s, avg_loss=3.02, ce=1.77, crd=1.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: val_orig: 50.62% | val_color: 38.03%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 38.03%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.80it/s, avg_loss=2.87, ce=1.68, crd=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: val_orig: 51.80% | val_color: 39.46%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 39.46%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.72, ce=1.59, crd=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: val_orig: 54.36% | val_color: 40.46%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 40.46%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.6, ce=1.52, crd=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: val_orig: 55.09% | val_color: 41.95%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 41.95%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.83it/s, avg_loss=2.48, ce=1.45, crd=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: val_orig: 55.97% | val_color: 42.05%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 42.05%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.37, ce=1.38, crd=0.987]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: val_orig: 56.76% | val_color: 43.13%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 43.13%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.27, ce=1.32, crd=0.952]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: val_orig: 57.79% | val_color: 44.35%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 44.35%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.17, ce=1.25, crd=0.922]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: val_orig: 57.93% | val_color: 44.93%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 44.93%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=2.08, ce=1.19, crd=0.892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: val_orig: 58.19% | val_color: 45.25%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 45.25%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.80it/s, avg_loss=1.99, ce=1.13, crd=0.863]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: val_orig: 58.75% | val_color: 44.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.90it/s, avg_loss=1.93, ce=1.08, crd=0.844]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: val_orig: 59.50% | val_color: 46.99%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 46.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.80it/s, avg_loss=1.85, ce=1.03, crd=0.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: val_orig: 60.31% | val_color: 46.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.89it/s, avg_loss=1.79, ce=0.984, crd=0.807]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: val_orig: 60.71% | val_color: 47.58%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 47.58%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.81it/s, avg_loss=1.74, ce=0.947, crd=0.794]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: val_orig: 60.92% | val_color: 47.96%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 47.96%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.79it/s, avg_loss=1.69, ce=0.909, crd=0.781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: val_orig: 61.17% | val_color: 47.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.88it/s, avg_loss=1.65, ce=0.884, crd=0.769]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: val_orig: 61.17% | val_color: 48.68%\n",
            "  -> Saved best student to /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth (val_color 48.68%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:57<00:00,  6.79it/s, avg_loss=1.63, ce=0.864, crd=0.761]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: val_orig: 61.38% | val_color: 48.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.89it/s, avg_loss=1.6, ce=0.84, crd=0.757]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: val_orig: 61.39% | val_color: 48.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.90it/s, avg_loss=1.59, ce=0.832, crd=0.754]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: val_orig: 61.66% | val_color: 47.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CRD student training epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [00:56<00:00,  6.88it/s, avg_loss=1.57, ce=0.822, crd=0.752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: val_orig: 61.84% | val_color: 48.50%\n",
            "CRD training complete. best color-val: 48.68\n",
            "=== Step C: Final evaluation summary ===\n",
            "Teacher (color-finetuned) - Orig test acc: 68.29% | Color test acc: 65.33%\n",
            "Student (CRD from color-teacher) - Orig test acc: 61.17% | Color test acc: 47.58%\n",
            "Total time (minutes): 45.88\n",
            "Logs saved to: /content/drive/MyDrive/crd_color_invariance_log.csv\n",
            "Outputs saved to: /content/drive/MyDrive/teacher_vgg16_colorfinetune.pth /content/drive/MyDrive/student_vgg11_CRD_colorteacher.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Efficacy of a Larger Teacher"
      ],
      "metadata": {
        "id": "GZ_u3MVytS1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# Part 6: Testing the Efficacy of a Larger Teacher (LM)\n",
        "# =====================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"ðŸš€ Using device: {device}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load Teacher Models\n",
        "# ---------------------------\n",
        "num_classes = 100  # CIFAR-100 (change to 10 if using CIFAR-10)\n",
        "\n",
        "# Teacher 1: VGG16\n",
        "teacher_vgg16 = models.vgg16(pretrained=False)\n",
        "teacher_vgg16.classifier[6] = nn.Linear(4096, num_classes)\n",
        "teacher_vgg16.load_state_dict(torch.load('/content/drive/MyDrive/teacher_vgg16.pth', map_location=device))\n",
        "teacher_vgg16.to(device).eval()\n",
        "print(\"âœ… Loaded Teacher: VGG16\")\n",
        "\n",
        "# Teacher 2: VGG19 (larger teacher)\n",
        "teacher_vgg19 = models.vgg19(pretrained=True)\n",
        "teacher_vgg19.classifier[6] = nn.Linear(4096, num_classes)\n",
        "teacher_vgg19.to(device).eval()\n",
        "print(\"âœ… Loaded Teacher: VGG19 (pretrained ImageNet weights)\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Student Model (VGG11)\n",
        "# ---------------------------\n",
        "def get_student_model():\n",
        "    model = models.vgg11(pretrained=False)\n",
        "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. KD Loss (Logit Matching)\n",
        "# ---------------------------\n",
        "def kd_loss(student_logits, teacher_logits, temperature=4.0):\n",
        "    T = temperature\n",
        "    loss_kd = F.kl_div(\n",
        "        F.log_softmax(student_logits / T, dim=1),\n",
        "        F.softmax(teacher_logits / T, dim=1),\n",
        "        reduction='batchmean'\n",
        "    ) * (T * T)\n",
        "    return loss_kd\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Training Function\n",
        "# ---------------------------\n",
        "def train_kd(student, teacher, trainloader, epochs=3, lr=1e-4, temperature=4.0, alpha=0.7):\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        teacher.eval()\n",
        "\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(images)\n",
        "\n",
        "            student_logits = student(images)\n",
        "            loss_ce = criterion(student_logits, labels)\n",
        "            loss_kd_val = kd_loss(student_logits, teacher_logits, temperature)\n",
        "            loss = alpha * loss_kd_val + (1 - alpha) * loss_ce\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            correct += (student_logits.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            acc = 100.0 * correct / total\n",
        "            pbar.set_postfix({\"Loss\": f\"{running_loss/total:.4f}\", \"Acc\": f\"{acc:.2f}%\"})\n",
        "\n",
        "        print(f\"ðŸ“˜ Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/total:.4f} | Acc: {acc:.2f}%\")\n",
        "\n",
        "    print(\"âœ… Training complete.\")\n",
        "    return student\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Dataset & Dataloaders\n",
        "# ---------------------------\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "valset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Train Student with VGG16\n",
        "# ---------------------------\n",
        "print(\"\\nðŸ”µ Training Student (VGG11) with Teacher VGG16\")\n",
        "student_vgg11_v16 = get_student_model()\n",
        "student_vgg11_v16 = train_kd(student_vgg11_v16, teacher_vgg16, trainloader, epochs=2)\n",
        "torch.save(student_vgg11_v16.state_dict(), \"/content/drive/MyDrive/student_vgg11_from_vgg16.pth\")\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Train Student with VGG19\n",
        "# ---------------------------\n",
        "print(\"\\nðŸŸ£ Training Student (VGG11) with Teacher VGG19\")\n",
        "student_vgg11_v19 = get_student_model()\n",
        "student_vgg11_v19 = train_kd(student_vgg11_v19, teacher_vgg19, trainloader, epochs=2)\n",
        "torch.save(student_vgg11_v19.state_dict(), \"/content/drive/MyDrive/student_vgg11_from_vgg19.pth\")\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Evaluation Function\n",
        "# ---------------------------\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# ---------------------------\n",
        "# 9. Compare Models\n",
        "# ---------------------------\n",
        "acc_v16 = evaluate(student_vgg11_v16, valloader)\n",
        "acc_v19 = evaluate(student_vgg11_v19, valloader)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Teacher Model\": [\"VGG16\", \"VGG19\"],\n",
        "    \"Teacher Size\": [\"Medium\", \"Large\"],\n",
        "    \"Student Model\": [\"VGG11\", \"VGG11\"],\n",
        "    \"Validation Accuracy (%)\": [acc_v16, acc_v19]\n",
        "})\n",
        "\n",
        "print(\"\\nðŸ“Š === Comparison: Teacher Size vs Student Performance ===\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "jOGV3XDohVFP",
        "outputId": "5b556e23-c646-44af-98d8-60270dcc38f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Using device: cuda\n",
            "âœ… Loaded Teacher: VGG16\n",
            "âœ… Loaded Teacher: VGG19 (pretrained ImageNet weights)\n",
            "\n",
            "ðŸ”µ Training Student (VGG11) with Teacher VGG16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Epoch [1/2] | Loss: 1.3846 | Acc: 6.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Epoch [2/2] | Loss: 1.1911 | Acc: 23.31%\n",
            "âœ… Training complete.\n",
            "\n",
            "ðŸŸ£ Training Student (VGG11) with Teacher VGG19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 40.12 MiB is free. Process 2539 has 14.70 GiB memory in use. Of the allocated memory 12.54 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2738895308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸŸ£ Training Student (VGG11) with Teacher VGG19\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mstudent_vgg11_v19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_student_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0mstudent_vgg11_v19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_kd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_vgg11_v19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_vgg19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_vgg11_v19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/student_vgg11_from_vgg19.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2738895308.py\u001b[0m in \u001b[0;36mtrain_kd\u001b[0;34m(student, teacher, trainloader, epochs, lr, temperature, alpha)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 784.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 40.12 MiB is free. Process 2539 has 14.70 GiB memory in use. Of the allocated memory 12.54 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QPp4aPzgvrkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OI8QgvKLx9eC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}